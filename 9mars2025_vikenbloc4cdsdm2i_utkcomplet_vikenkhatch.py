# -*- coding: utf-8 -*-
"""9Mars2025_VikenBloc4CDSDM2i_utkcomplet_vikenkhatch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14rHjLzty9-TqqzIScea02BsP2HXrdMZ4
"""

# Installation de google drive
from google.colab import drive
drive.mount('/content/drive')

# chargement des bibliothèques
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, Callback
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Chargement et exploration des données
data_dir = "/content/drive/MyDrive/utkcropped"
file_paths = []
ages = []

for file in os.listdir(data_dir):
    if file.endswith(".jpg"):
        age = int(file.split("_")[0])
        file_paths.append(os.path.join(data_dir, file))
        ages.append(age)

# Création d'un DataFrame
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

df = pd.DataFrame({"file_path": file_paths, "age": ages})
df.head()

# affichage du nombre de lignes et de colonnes du dataframe
df.shape

# Visualisation de la distribution des âges
plt.figure(figsize=(10, 6))
sns.histplot(df["age"], bins=30, kde=True)
plt.title("Distribution des âges dans UTKFace")
plt.show()

# Violin plot
plt.figure(figsize=(10, 6))
sns.violinplot(y=df["age"])
plt.title("Répartition des âges")
plt.show()

df.describe()

# Préparation des données
img_height, img_width = 200, 200
batch_size = 32

def process_image(file_path, label):
    img = tf.io.read_file(file_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width]) / 255.0
    return img, label

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age"], test_size=0.2, random_state=42)

train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

# Data Augmentation
data_augmentation = Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

# Modèle CNN pour la régression (prédiction d'âge)
model_regression = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(1)
])

model_regression.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Entraînement

# Fichiers pour sauvegarder les poids et l'état des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_epoch_checkpoint.txt'

# Définir un callback personnalisé pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch terminée (epoch commence à 0)

# Vérifier si un checkpoint existe déjà et récupérer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegardés...")
    model_regression.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch déjà faite
        print(f"Reprise à l'epoch {initial_epoch}")

# Définir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entraînement en ne faisant que les epochs restantes
total_epochs = 15  # Nombre total d'epochs prévu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entraînement pour {remaining_epochs} epochs restantes...")
    history_reg = model_regression.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistrée
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver])

    # Sauvegarde du modèle complet après l'entraînement
    model_regression.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model.h5')
    print("Modèle final sauvegardé sous viken_bloc4_cdsd_m2i_age_detection_model.h5")

else:
    print("Entraînement déjà terminé !")

# Modèle CNN pour la classification par classes d'âge
bins = [0, 10, 20, 30, 40, 60, 80, np.inf]
labels = [0, 1, 2, 3, 4, 5, 6]
df["age_group"] = pd.cut(df["age"], bins=bins, labels=labels)

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age_group"].astype(int), test_size=0.2, random_state=42)
train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

model_classification = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(len(labels), activation='softmax')
])

model_classification.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Entraînement

# Fichiers pour sauvegarder les poids et l'état des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_model_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_epoch_checkpoint.txt'

# Définir un callback personnalisé pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch terminée (epoch commence à 0)

# Vérifier si un checkpoint existe déjà et récupérer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegardés...")
    model_classification.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch déjà faite
        print(f"Reprise à l'epoch {initial_epoch}")

# Définir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entraînement en ne faisant que les epochs restantes
total_epochs = 15  # Nombre total d'epochs prévu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entraînement pour {remaining_epochs} epochs restantes...")
    history_class = model_classification.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistrée
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver])

    # Sauvegarde du modèle complet après l'entraînement
    model_classification.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_model.h5')
    print("Modèle final sauvegardé sous viken_bloc4_cdsd_m2i_age_classification_model.h5")

else:
    print("Entraînement déjà terminé !")

# Évaluation
y_pred_reg = model_regression.predict(test_data).flatten()
y_pred_class = np.argmax(model_classification.predict(test_data), axis=1)

mae = np.mean(np.abs(y_pred_reg - y_test))
accuracy = accuracy_score(y_test, y_pred_class)
precision = precision_score(y_test, y_pred_class, average='weighted')
recall = recall_score(y_test, y_pred_class, average='weighted')
f1 = f1_score(y_test, y_pred_class, average='weighted')
cm = confusion_matrix(y_test, y_pred_class)

# Affichage des résultats
print(f"MAE (Régression) : {mae}")
print(f"Accuracy (Classification) : {accuracy}")
print(f"Precision : {precision}")
print(f"Recall : {recall}")
print(f"F1-score : {f1}")
print("Matrice de confusion :\n", cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Prédit")
plt.ylabel("Réel")
plt.show()

# Affichage de la heatmap avec les bonnes étiquettes pour les classes
plt.figure(figsize=(8, 6))

# Remplacer les étiquettes par les tranches d'âge dans la matrice de confusion
age_groups = ['0-10', '10-20', '20-30', '30-40', '40-60', '60-80', '80+']  # Correspond aux labels des bins

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=age_groups, yticklabels=age_groups)

plt.xlabel("Âge Prédit (an(s))")
plt.ylabel("Âge Réel (an(s))")
plt.title("Matrice de Confusion avec Tranches d'Âge")
plt.show()

# Récupérer les valeurs de loss et MAE depuis l'entraînement
loss = history_reg.history['loss']
val_loss = history_reg.history['val_loss']
mae = history_reg.history['mae']
val_mae = history_reg.history['val_mae']

# Tracer les courbes de loss et MAE
plt.figure(figsize=(12, 6))

# Courbes de Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, 16), loss, label="Training Loss")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - régession prédire âge')
plt.legend()

# Courbes de MAE (Mean Absolute Error)
plt.subplot(1, 2, 2)
plt.plot(range(1, 16), mae, label="Training MAE")
plt.plot(range(1, 16), val_mae, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Training and Validation MAE - régression prédire âge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Tracer les courbes de loss et MAE pour l'entraînement et la validation
plt.figure(figsize=(12, 6))

# Loss et MAE pour l'entraînement
plt.subplot(1, 2, 1)
# Courbe de Loss pour l'entraînement
plt.plot(range(1, 16), loss, label="Training Loss")
# Courbe de MAE pour l'entraînement
plt.plot(range(1, 16), mae, label="Training MAE")
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Training Loss & MAE - régression prédire âge')
plt.legend()

# Loss et MAE pour la validation
plt.subplot(1, 2, 2)  # 1 ligne, 2 colonnes, deuxième vignette
# Courbe de Loss pour la validation
plt.plot(range(1, 16), val_loss, label="Validation Loss")
# Courbe de MAE pour la validation
plt.plot(range(1, 16), val_mae, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Validation Loss & MAE - régression prédire âge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Récupération des données d'accuracy et de loss (classification multi-classes)
acc = history_class.history['accuracy']
val_acc = history_class.history['val_accuracy']
loss = history_class.history['loss']
val_loss = history_class.history['val_loss']

# Tracer les courbes de comparaison de l'accuracy et de loss entre training et validation (test)
plt.figure(figsize=(12, 6))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(range(1, 16), acc, label="Training Accuracy")
plt.plot(range(1, 16), val_acc, label="Validation Accuracy")
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy - classification âge multi-classes')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(range(1, 16), loss, label="Training Loss")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - classification âge multi-classes')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Tracer pour chacun des ensembles d'entraînement et de test les courbes de l'accuracy et de loss
plt.figure(figsize=(24, 6))  # Augmenter la largeur pour accueillir 4 subplots

# Training Accuracy and Loss
plt.subplot(1, 4, 3)  # 1 ligne, 4 colonnes, 3e subplot
plt.plot(range(1, 16), acc, label="Accuracy")
plt.plot(range(1, 16), loss, label="Loss")
plt.xlabel('Epochs')
plt.title('Training Accuracy and Loss - classification âge multi-classes')
plt.legend()

# Validation Accuracy and Loss
plt.subplot(1, 4, 4)  # 1 ligne, 4 colonnes, 4e subplot
plt.plot(range(1, 16), val_acc, label="Validation Accuracy")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Metrics')
plt.title('Validation Accuracy and Loss - classification âge multi-classes')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

import os
import random
import tensorflow as tf
import matplotlib.pyplot as plt

# Chemin du dossier contenant les images du dataset n'ayant ni participé à l'entraînement ni participé au test du modèle de détection de l'âge
test_folder = "drive/MyDrive/utkcroppedpredict"

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# Vérifier s'il y a des images dans le dossier
if not image_files:
    print("Aucune image trouvée dans le dossier !")
else:
    # Sélectionner un fichier image au hasard
    random_file = random.choice(image_files)
    file_path = os.path.join(test_folder, random_file)

    # Extraire l'âge réel à partir du nom du fichier (avant le premier "_")
    real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

    # Charger et prétraiter l'image
    image, _ = process_image(file_path, real_age)  # Passer l'âge réel pour affichage si nécessaire

    # Affichage de l'image
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.axis('off')

    # Prédire l'âge avec le modèle
    predicted_age = model_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

    # Afficher l'âge réel et l'âge prédit
    plt.title(f"Âge réel: {real_age}, Âge prédit: {predicted_age:.2f}")
    plt.show()

# Nombre d'images à afficher
num_images = 5

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# Vérifier s'il y a suffisamment d'images dans le dossier
if len(image_files) < num_images:
    print(f"Seulement {len(image_files)} images disponibles, ajustez `num_images`.")
else:
    # Créer une figure pour afficher les images
    plt.figure(figsize=(15, 15))

    # Sélectionner et afficher plusieurs images aléatoires
    for i in range(num_images):
        # Sélectionner un fichier image au hasard
        random_file = random.choice(image_files)
        file_path = os.path.join(test_folder, random_file)

        # Extraire l'âge réel à partir du nom du fichier (avant le premier "_")
        real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

        # Charger et prétraiter l'image
        image, _ = process_image(file_path, real_age)  # Passer l'âge réel pour affichage si nécessaire

        # Prédire l'âge de l'image avec le modèle de régression
        predicted_age = model_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

        # Afficher l'image dans un sous-graphe (médaillon)
        plt.subplot(1, num_images, i + 1)  # 1 ligne et 'num_images' colonnes
        plt.imshow(image)
        plt.axis('off')

        # Afficher l'âge réel et prédit sur l'image
        plt.title(f"Réel: {real_age}, Prédit: {predicted_age:.2f}")

    # Affichage de toutes les images
    plt.tight_layout()
    plt.show()

# Essai prédiction d'âge avec photo nouvelle
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
from tensorflow.keras.losses import MeanSquaredError

model = load_model('/content/drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model.h5',
                   custom_objects={'mse': MeanSquaredError()})  # Corrige l'erreur de 'mse'

print("Modèle chargé avec succès !")

# Essai de prédiciton d'âge avec photos nouvelles non vues par le modèle et n'appartenant pas au dataset
import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de prétraitement pour une image
def process_image(image_path, target_size=(200, 200)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
    img_resized = cv2.resize(img, target_size)  # Redimensionner
    img_array = np.expand_dims(img_resized, axis=0) / 255.0  # Ajouter batch & normaliser
    return img_array, img_resized  # Retourne aussi l'image redimensionnée pour affichage

# Chemins des trois images
image_path1 = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace par ton chemin
image_path2 = '/content/drive/MyDrive/VikMaIMG-20250308-WA0000.jpg'  # Remplace par ton chemin
image_path3 = '/content/drive/MyDrive/VikPaIMG-20250308-WA0001.jpg'  # Remplace par ton chemin

# Charger les images
image_array1, img_resized1 = process_image(image_path1)
image_array2, img_resized2 = process_image(image_path2)
image_array3, img_resized3 = process_image(image_path3)

# Prédire les âges
predicted_age1 = model.predict(image_array1).flatten()[0]
predicted_age2 = model.predict(image_array2).flatten()[0]
predicted_age3 = model.predict(image_array3).flatten()[0]

# Afficher les images avec les âges prédits
fig, axes = plt.subplots(1, 3, figsize=(20, 5))  # 3 images en ligne

axes[0].imshow(img_resized1)
axes[0].axis('off')
axes[0].set_title(f"Âge prédit : {predicted_age1:.2f}")

axes[1].imshow(img_resized2)
axes[1].axis('off')
axes[1].set_title(f"Âge prédit : {predicted_age2:.2f}")

axes[2].imshow(img_resized3)
axes[2].axis('off')
axes[2].set_title(f"Âge prédit : {predicted_age3:.2f}")

plt.show()

""" Le modèle fonctionne correctement sur UTKFace mais mal sur d’autres images, ce qui suggère un problème de généralisation.

 Causes possibles :

-Erreur moyenne absolue élevée. L'écart entre loss et val_loss est significatif (mae_train = 7.9895 ans et mae_validation = 8.5913 ans) ce qui suggère un sur-apprentissage du modèle de régression qui est meilleur sur les données d'entraînement mais perd en précision sur la validation et la présentation d'images que le modèle n'a pas vues. La loss d'entraînement est plus basse que la loss de validation. Le modèle s’adapte trop aux images UTKFace mais ne généralise pas bien.

Solutions possibles:

-Ajouter d'autres bases de données d'images contenant plus de diversité.

-Essayer un modèle pré-entraîné (Transfer Learning) comme  ResNet ou EfficientNet

-Ajouter des transformations dans la data augmentation (contraste, luminosité, cisaillement (visage incliné), bruit)

-Entraîner plus longtemps avec Early Stopping : le modèle a été entraîné sur
15 epochs ce qui peut être insuffisant donc ajouter un EarlyStopping pour éviter le sur-apprentissage et augmenter le nombre d'epochs

-Ajouter un Dropout (0.3-0.5) dans la partie dense

-Ajouter une régularisation L2 sur la dernière couche dense pour éviter que le modèle s'ajuste trop aux données d'entraînement

Décision pour la suite :

-Ajout d'une 4e couche de convolution avec 256 filtres
pour tenter d'extraire des caractéristiques plus complexes

-Apprentissage de ces caractéristiques complexes par une couche layer Dense avec 256 neurones

-Ajout d'une fonction Early Stopping permettant l'arrêt prématuré de l'entraînement si pas de progrès significatif sur mae et val_mae

-Ajuster dynamiquement le taux d'apprentissage pendant l'entraînement pour aider le modèle à converger vers un meilleur pouvoir de prédiction







"""

# Installation de google drive
from google.colab import drive
drive.mount('/content/drive')

# Essai amélioration du modèle de régression
# chargement des bibliothèques
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, Callback
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Chargement et exploration des données
data_dir = "/content/drive/MyDrive/utkcropped"
file_paths = []
ages = []

for file in os.listdir(data_dir):
    if file.endswith(".jpg"):
        age = int(file.split("_")[0])
        file_paths.append(os.path.join(data_dir, file))
        ages.append(age)

# Préparation des données
img_height, img_width = 200, 200
batch_size = 32

def gaussian_blur(image):
    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.02)  # Ajout de bruit léger
    return tf.clip_by_value(image + noise, 0.0, 1.0)  # Garde les valeurs entre [0,1]

def process_image(file_path, label):
    img = tf.io.read_file(file_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width]) / 255.0

    #img = gaussian_blur(img)  # 🔹 Ajout du flou (bruit gaussien léger)

    return img, label

# Création d'un DataFrame
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

df = pd.DataFrame({"file_path": file_paths, "age": ages})
df.head()

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age"], test_size=0.2, random_state=42)

train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

data_augmentation = Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1)
])

# Essai amélioration Modèle CNN pour la régression (prédiction d'âge)
model5_regression = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Conv2D(256, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(1)
])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

model5_regression.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Définir le callback ReduceLROnPlateau (ajustement dynamique du taux d'apprentissage)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',  # Surveiller la perte de validation
    factor=0.5,          # Réduire le taux d'apprentissage par un facteur de 0.5
    patience=5,          # Nombre d'epochs sans amélioration avant de réduire le taux d'apprentissage
    verbose=1            # Afficher un message lorsqu'il y a réduction du taux d'apprentissage
)

# Entraînement

# Fichiers pour sauvegarder les poids et l'état des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model5_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_epoch5_checkpoint.txt'

# Définir un callback personnalisé pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch terminée (epoch commence à 0)

# Vérifier si un checkpoint existe déjà et récupérer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegardés...")
    model5_regression.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch déjà faite
        print(f"Reprise à l'epoch {initial_epoch}")

# Définir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entraînement en ne faisant que les epochs restantes
total_epochs = 30  # Nombre total d'epochs prévu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entraînement pour {remaining_epochs} epochs restantes...")
    history_reg5 = model5_regression.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistrée
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver, reduce_lr, early_stopping])

    # Sauvegarde du modèle complet après l'entraînement
    model5_regression.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model5.h5')
    print("Modèle final sauvegardé sous viken_bloc4_cdsd_m2i_age_detection_model5.h5")

else:
    print("Entraînement déjà terminé !")

# Évaluation
y_pred_reg5 = model5_regression.predict(test_data).flatten()

mae5 = np.mean(np.abs(y_pred_reg5 - y_test))

# Affichage des résultats
print(f"MAE (Régression) : {mae5}")

# Récupérer les valeurs de loss et MAE depuis l'entraînement
loss5 = history_reg5.history['loss']
val_loss5 = history_reg5.history['val_loss']
mae5 = history_reg5.history['mae']
val_mae5 = history_reg5.history['val_mae']

# Tracer les courbes de loss et MAE
# Tracer les courbes de loss et MAE
plt.figure(figsize=(12, 6))

# Courbes de Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, 31), loss5, label="Training Loss")
plt.plot(range(1, 31), val_loss5, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - régression prédire âge')
plt.legend()

# Courbes de MAE (Mean Absolute Error)
plt.subplot(1, 2, 2)
plt.plot(range(1, 31), mae5, label="Training MAE")
plt.plot(range(1, 31), val_mae5, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Training and Validation MAE - régression prédire âge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()

"""Avant la diminution dynamique du taux d'apprentissage à la 19e epoch, le modèle fait des sauts trop brusques dans la descente de gradient, ce qui cause des oscillations (0,001 apparaît donc comme un taux d'apprentissage trop grand).
Le passage de ce taux à 5e-4 diminue significativement ces oscillations ce qui aide le modèle à converger vers un meilleur pouvoir de prédiction.

"""

# Tracer les courbes de loss et MAE pour l'entraînement et la validation
plt.figure(figsize=(12, 6))

# Loss et MAE pour l'entraînement
plt.subplot(1, 2, 1)
# Courbe de Loss pour l'entraînement
plt.plot(range(1, 31), loss5, label="Training Loss")  # Plage ajustée à 30 epochs
# Courbe de MAE pour l'entraînement
plt.plot(range(1, 31), mae5, label="Training MAE")  # Plage ajustée à 30 epochs
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Training Loss & MAE - régression prédire âge')
plt.legend()

# Loss et MAE pour la validation
plt.subplot(1, 2, 2)  # 1 ligne, 2 colonnes, deuxième vignette
# Courbe de Loss pour la validation
plt.plot(range(1, 31), val_loss5, label="Validation Loss")  # Plage ajustée à 30 epochs
# Courbe de MAE pour la validation
plt.plot(range(1, 31), val_mae5, label="Validation MAE")  # Plage ajustée à 30 epochs
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Validation Loss & MAE - régression prédire âge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Essai modèle 2
import os
import random
import tensorflow as tf
import matplotlib.pyplot as plt

# Chemin du dossier contenant les images du dataset n'ayant ni participé à l'entraînement ni participé au test du modèle de détection de l'âge
test_folder = "drive/MyDrive/utkcroppedpredict"

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# Vérifier s'il y a des images dans le dossier
if not image_files:
    print("Aucune image trouvée dans le dossier !")
else:
    # Sélectionner un fichier image au hasard
    random_file = random.choice(image_files)
    file_path = os.path.join(test_folder, random_file)

    # Extraire l'âge réel à partir du nom du fichier (avant le premier "_")
    real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

    # Charger et prétraiter l'image
    image, _ = process_image(file_path, real_age)  # Passer l'âge réel pour affichage si nécessaire

    # Affichage de l'image
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.axis('off')

    # Prédire l'âge avec le modèle
    predicted_age = model5_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

    # Afficher l'âge réel et l'âge prédit
    plt.title(f"Âge réel: {real_age}, Âge prédit: {predicted_age:.2f}")
    plt.show()

# Nombre d'images à afficher
num_images = 5

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# Vérifier s'il y a suffisamment d'images dans le dossier
if len(image_files) < num_images:
    print(f"Seulement {len(image_files)} images disponibles, ajustez `num_images`.")
else:
    # Créer une figure pour afficher les images
    plt.figure(figsize=(15, 15))

    # Sélectionner et afficher plusieurs images aléatoires
    for i in range(num_images):
        # Sélectionner un fichier image au hasard
        random_file = random.choice(image_files)
        file_path = os.path.join(test_folder, random_file)

        # Extraire l'âge réel à partir du nom du fichier (avant le premier "_")
        real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

        # Charger et prétraiter l'image
        image, _ = process_image(file_path, real_age)  # Passer l'âge réel pour affichage si nécessaire

        # Prédire l'âge de l'image avec le modèle de régression
        predicted_age = model5_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

        # Afficher l'image dans un sous-graphe (médaillon)
        plt.subplot(1, num_images, i + 1)  # 1 ligne et 'num_images' colonnes
        plt.imshow(image)
        plt.axis('off')

        # Afficher l'âge réel et prédit sur l'image
        plt.title(f"Réel: {real_age}, Prédit: {predicted_age:.2f}")

    # Affichage de toutes les images
    plt.tight_layout()
    plt.show()

# Essai prédiction d'âge avec photo nouvelle
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
from tensorflow.keras.losses import MeanSquaredError

model = load_model('/content/drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model5.h5',
                   custom_objects={'mse': MeanSquaredError()})  # Corrige l'erreur de 'mse'

print("Modèle chargé avec succès !")

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de prétraitement pour une image
def process_image(image_path, target_size=(200, 200)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
    img_resized = cv2.resize(img, target_size)  # Redimensionner
    img_array = np.expand_dims(img_resized, axis=0) / 255.0  # Ajouter batch & normaliser
    return img_array, img_resized  # Retourne aussi l'image redimensionnée pour affichage

# Chemins des trois images
image_path1 = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace par ton chemin
image_path2 = '/content/drive/MyDrive/VikMaIMG-20250308-WA0000.jpg'  # Remplace par ton chemin
image_path3 = '/content/drive/MyDrive/VikPaIMG-20250308-WA0001.jpg'  # Remplace par ton chemin

# Charger les images
image_array1, img_resized1 = process_image(image_path1)
image_array2, img_resized2 = process_image(image_path2)
image_array3, img_resized3 = process_image(image_path3)

# Prédire les âges
predicted_age1 = model.predict(image_array1).flatten()[0]
predicted_age2 = model.predict(image_array2).flatten()[0]
predicted_age3 = model.predict(image_array3).flatten()[0]

# Afficher les images avec les âges prédits
fig, axes = plt.subplots(1, 3, figsize=(20, 5))  # 3 images en ligne

axes[0].imshow(img_resized1)
axes[0].axis('off')
axes[0].set_title(f"Âge prédit : {predicted_age1:.2f}")

axes[1].imshow(img_resized2)
axes[1].axis('off')
axes[1].set_title(f"Âge prédit : {predicted_age2:.2f}")

axes[2].imshow(img_resized3)
axes[2].axis('off')
axes[2].set_title(f"Âge prédit : {predicted_age3:.2f}")

plt.show()

