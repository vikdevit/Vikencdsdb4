# -*- coding: utf-8 -*-
"""9Mars2025_VikenBloc4CDSDM2i_utkcomplet_vikenkhatch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14rHjLzty9-TqqzIScea02BsP2HXrdMZ4
"""

# Installation de google drive
from google.colab import drive
drive.mount('/content/drive')

# chargement des biblioth√®ques
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, Callback
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Chargement et exploration des donn√©es
data_dir = "/content/drive/MyDrive/utkcropped"
file_paths = []
ages = []

for file in os.listdir(data_dir):
    if file.endswith(".jpg"):
        age = int(file.split("_")[0])
        file_paths.append(os.path.join(data_dir, file))
        ages.append(age)

# Cr√©ation d'un DataFrame
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

df = pd.DataFrame({"file_path": file_paths, "age": ages})
df.head()

# affichage du nombre de lignes et de colonnes du dataframe
df.shape

# Visualisation de la distribution des √¢ges
plt.figure(figsize=(10, 6))
sns.histplot(df["age"], bins=30, kde=True)
plt.title("Distribution des √¢ges dans UTKFace")
plt.show()

# Violin plot
plt.figure(figsize=(10, 6))
sns.violinplot(y=df["age"])
plt.title("R√©partition des √¢ges")
plt.show()

df.describe()

# Pr√©paration des donn√©es
img_height, img_width = 200, 200
batch_size = 32

def process_image(file_path, label):
    img = tf.io.read_file(file_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width]) / 255.0
    return img, label

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age"], test_size=0.2, random_state=42)

train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

# Data Augmentation
data_augmentation = Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

# Mod√®le CNN pour la r√©gression (pr√©diction d'√¢ge)
model_regression = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(1)
])

model_regression.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Entra√Ænement

# Fichiers pour sauvegarder les poids et l'√©tat des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_epoch_checkpoint.txt'

# D√©finir un callback personnalis√© pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch termin√©e (epoch commence √† 0)

# V√©rifier si un checkpoint existe d√©j√† et r√©cup√©rer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegard√©s...")
    model_regression.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch d√©j√† faite
        print(f"Reprise √† l'epoch {initial_epoch}")

# D√©finir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entra√Ænement en ne faisant que les epochs restantes
total_epochs = 15  # Nombre total d'epochs pr√©vu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entra√Ænement pour {remaining_epochs} epochs restantes...")
    history_reg = model_regression.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistr√©e
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver])

    # Sauvegarde du mod√®le complet apr√®s l'entra√Ænement
    model_regression.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model.h5')
    print("Mod√®le final sauvegard√© sous viken_bloc4_cdsd_m2i_age_detection_model.h5")

else:
    print("Entra√Ænement d√©j√† termin√© !")

# Mod√®le CNN pour la classification par classes d'√¢ge
bins = [0, 10, 20, 30, 40, 60, 80, np.inf]
labels = [0, 1, 2, 3, 4, 5, 6]
df["age_group"] = pd.cut(df["age"], bins=bins, labels=labels)

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age_group"].astype(int), test_size=0.2, random_state=42)
train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

model_classification = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(len(labels), activation='softmax')
])

model_classification.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Entra√Ænement

# Fichiers pour sauvegarder les poids et l'√©tat des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_model_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_epoch_checkpoint.txt'

# D√©finir un callback personnalis√© pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch termin√©e (epoch commence √† 0)

# V√©rifier si un checkpoint existe d√©j√† et r√©cup√©rer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegard√©s...")
    model_classification.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch d√©j√† faite
        print(f"Reprise √† l'epoch {initial_epoch}")

# D√©finir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entra√Ænement en ne faisant que les epochs restantes
total_epochs = 15  # Nombre total d'epochs pr√©vu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entra√Ænement pour {remaining_epochs} epochs restantes...")
    history_class = model_classification.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistr√©e
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver])

    # Sauvegarde du mod√®le complet apr√®s l'entra√Ænement
    model_classification.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_model.h5')
    print("Mod√®le final sauvegard√© sous viken_bloc4_cdsd_m2i_age_classification_model.h5")

else:
    print("Entra√Ænement d√©j√† termin√© !")

# √âvaluation
y_pred_reg = model_regression.predict(test_data).flatten()
y_pred_class = np.argmax(model_classification.predict(test_data), axis=1)

mae = np.mean(np.abs(y_pred_reg - y_test))
accuracy = accuracy_score(y_test, y_pred_class)
precision = precision_score(y_test, y_pred_class, average='weighted')
recall = recall_score(y_test, y_pred_class, average='weighted')
f1 = f1_score(y_test, y_pred_class, average='weighted')
cm = confusion_matrix(y_test, y_pred_class)

# Affichage des r√©sultats
print(f"MAE (R√©gression) : {mae}")
print(f"Accuracy (Classification) : {accuracy}")
print(f"Precision : {precision}")
print(f"Recall : {recall}")
print(f"F1-score : {f1}")
print("Matrice de confusion :\n", cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Pr√©dit")
plt.ylabel("R√©el")
plt.show()

# Affichage de la heatmap avec les bonnes √©tiquettes pour les classes
plt.figure(figsize=(8, 6))

# Remplacer les √©tiquettes par les tranches d'√¢ge dans la matrice de confusion
age_groups = ['0-10', '10-20', '20-30', '30-40', '40-60', '60-80', '80+']  # Correspond aux labels des bins

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=age_groups, yticklabels=age_groups)

plt.xlabel("√Çge Pr√©dit (an(s))")
plt.ylabel("√Çge R√©el (an(s))")
plt.title("Matrice de Confusion avec Tranches d'√Çge")
plt.show()

# R√©cup√©rer les valeurs de loss et MAE depuis l'entra√Ænement
loss = history_reg.history['loss']
val_loss = history_reg.history['val_loss']
mae = history_reg.history['mae']
val_mae = history_reg.history['val_mae']

# Tracer les courbes de loss et MAE
plt.figure(figsize=(12, 6))

# Courbes de Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, 16), loss, label="Training Loss")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - r√©gession pr√©dire √¢ge')
plt.legend()

# Courbes de MAE (Mean Absolute Error)
plt.subplot(1, 2, 2)
plt.plot(range(1, 16), mae, label="Training MAE")
plt.plot(range(1, 16), val_mae, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Training and Validation MAE - r√©gression pr√©dire √¢ge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Tracer les courbes de loss et MAE pour l'entra√Ænement et la validation
plt.figure(figsize=(12, 6))

# Loss et MAE pour l'entra√Ænement
plt.subplot(1, 2, 1)
# Courbe de Loss pour l'entra√Ænement
plt.plot(range(1, 16), loss, label="Training Loss")
# Courbe de MAE pour l'entra√Ænement
plt.plot(range(1, 16), mae, label="Training MAE")
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Training Loss & MAE - r√©gression pr√©dire √¢ge')
plt.legend()

# Loss et MAE pour la validation
plt.subplot(1, 2, 2)  # 1 ligne, 2 colonnes, deuxi√®me vignette
# Courbe de Loss pour la validation
plt.plot(range(1, 16), val_loss, label="Validation Loss")
# Courbe de MAE pour la validation
plt.plot(range(1, 16), val_mae, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Validation Loss & MAE - r√©gression pr√©dire √¢ge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# R√©cup√©ration des donn√©es d'accuracy et de loss (classification multi-classes)
acc = history_class.history['accuracy']
val_acc = history_class.history['val_accuracy']
loss = history_class.history['loss']
val_loss = history_class.history['val_loss']

# Tracer les courbes de comparaison de l'accuracy et de loss entre training et validation (test)
plt.figure(figsize=(12, 6))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(range(1, 16), acc, label="Training Accuracy")
plt.plot(range(1, 16), val_acc, label="Validation Accuracy")
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy - classification √¢ge multi-classes')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(range(1, 16), loss, label="Training Loss")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - classification √¢ge multi-classes')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Tracer pour chacun des ensembles d'entra√Ænement et de test les courbes de l'accuracy et de loss
plt.figure(figsize=(24, 6))  # Augmenter la largeur pour accueillir 4 subplots

# Training Accuracy and Loss
plt.subplot(1, 4, 3)  # 1 ligne, 4 colonnes, 3e subplot
plt.plot(range(1, 16), acc, label="Accuracy")
plt.plot(range(1, 16), loss, label="Loss")
plt.xlabel('Epochs')
plt.title('Training Accuracy and Loss - classification √¢ge multi-classes')
plt.legend()

# Validation Accuracy and Loss
plt.subplot(1, 4, 4)  # 1 ligne, 4 colonnes, 4e subplot
plt.plot(range(1, 16), val_acc, label="Validation Accuracy")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Metrics')
plt.title('Validation Accuracy and Loss - classification √¢ge multi-classes')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

import os
import random
import tensorflow as tf
import matplotlib.pyplot as plt

# Chemin du dossier contenant les images du dataset n'ayant ni particip√© √† l'entra√Ænement ni particip√© au test du mod√®le de d√©tection de l'√¢ge
test_folder = "drive/MyDrive/utkcroppedpredict"

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# V√©rifier s'il y a des images dans le dossier
if not image_files:
    print("Aucune image trouv√©e dans le dossier !")
else:
    # S√©lectionner un fichier image au hasard
    random_file = random.choice(image_files)
    file_path = os.path.join(test_folder, random_file)

    # Extraire l'√¢ge r√©el √† partir du nom du fichier (avant le premier "_")
    real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

    # Charger et pr√©traiter l'image
    image, _ = process_image(file_path, real_age)  # Passer l'√¢ge r√©el pour affichage si n√©cessaire

    # Affichage de l'image
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.axis('off')

    # Pr√©dire l'√¢ge avec le mod√®le
    predicted_age = model_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

    # Afficher l'√¢ge r√©el et l'√¢ge pr√©dit
    plt.title(f"√Çge r√©el: {real_age}, √Çge pr√©dit: {predicted_age:.2f}")
    plt.show()

# Nombre d'images √† afficher
num_images = 5

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# V√©rifier s'il y a suffisamment d'images dans le dossier
if len(image_files) < num_images:
    print(f"Seulement {len(image_files)} images disponibles, ajustez `num_images`.")
else:
    # Cr√©er une figure pour afficher les images
    plt.figure(figsize=(15, 15))

    # S√©lectionner et afficher plusieurs images al√©atoires
    for i in range(num_images):
        # S√©lectionner un fichier image au hasard
        random_file = random.choice(image_files)
        file_path = os.path.join(test_folder, random_file)

        # Extraire l'√¢ge r√©el √† partir du nom du fichier (avant le premier "_")
        real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

        # Charger et pr√©traiter l'image
        image, _ = process_image(file_path, real_age)  # Passer l'√¢ge r√©el pour affichage si n√©cessaire

        # Pr√©dire l'√¢ge de l'image avec le mod√®le de r√©gression
        predicted_age = model_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

        # Afficher l'image dans un sous-graphe (m√©daillon)
        plt.subplot(1, num_images, i + 1)  # 1 ligne et 'num_images' colonnes
        plt.imshow(image)
        plt.axis('off')

        # Afficher l'√¢ge r√©el et pr√©dit sur l'image
        plt.title(f"R√©el: {real_age}, Pr√©dit: {predicted_age:.2f}")

    # Affichage de toutes les images
    plt.tight_layout()
    plt.show()

# Essai pr√©diction d'√¢ge avec photo nouvelle
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
from tensorflow.keras.losses import MeanSquaredError

model = load_model('/content/drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model.h5',
                   custom_objects={'mse': MeanSquaredError()})  # Corrige l'erreur de 'mse'

print("Mod√®le charg√© avec succ√®s !")

# Essai de pr√©diciton d'√¢ge avec photos nouvelles non vues par le mod√®le et n'appartenant pas au dataset
import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de pr√©traitement pour une image
def process_image(image_path, target_size=(200, 200)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
    img_resized = cv2.resize(img, target_size)  # Redimensionner
    img_array = np.expand_dims(img_resized, axis=0) / 255.0  # Ajouter batch & normaliser
    return img_array, img_resized  # Retourne aussi l'image redimensionn√©e pour affichage

# Chemins des trois images
image_path1 = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace par ton chemin
image_path2 = '/content/drive/MyDrive/VikMaIMG-20250308-WA0000.jpg'  # Remplace par ton chemin
image_path3 = '/content/drive/MyDrive/VikPaIMG-20250308-WA0001.jpg'  # Remplace par ton chemin

# Charger les images
image_array1, img_resized1 = process_image(image_path1)
image_array2, img_resized2 = process_image(image_path2)
image_array3, img_resized3 = process_image(image_path3)

# Pr√©dire les √¢ges
predicted_age1 = model.predict(image_array1).flatten()[0]
predicted_age2 = model.predict(image_array2).flatten()[0]
predicted_age3 = model.predict(image_array3).flatten()[0]

# Afficher les images avec les √¢ges pr√©dits
fig, axes = plt.subplots(1, 3, figsize=(20, 5))  # 3 images en ligne

axes[0].imshow(img_resized1)
axes[0].axis('off')
axes[0].set_title(f"√Çge pr√©dit : {predicted_age1:.2f}")

axes[1].imshow(img_resized2)
axes[1].axis('off')
axes[1].set_title(f"√Çge pr√©dit : {predicted_age2:.2f}")

axes[2].imshow(img_resized3)
axes[2].axis('off')
axes[2].set_title(f"√Çge pr√©dit : {predicted_age3:.2f}")

plt.show()

""" Le mod√®le fonctionne correctement sur UTKFace mais mal sur d‚Äôautres images, ce qui sugg√®re un probl√®me de g√©n√©ralisation.

 Causes possibles :

-Erreur moyenne absolue √©lev√©e. L'√©cart entre loss et val_loss est significatif (mae_train = 7.9895 ans et mae_validation = 8.5913 ans) ce qui sugg√®re un sur-apprentissage du mod√®le de r√©gression qui est meilleur sur les donn√©es d'entra√Ænement mais perd en pr√©cision sur la validation et la pr√©sentation d'images que le mod√®le n'a pas vues. La loss d'entra√Ænement est plus basse que la loss de validation. Le mod√®le s‚Äôadapte trop aux images UTKFace mais ne g√©n√©ralise pas bien.

Solutions possibles:

-Ajouter d'autres bases de donn√©es d'images contenant plus de diversit√©.

-Essayer un mod√®le pr√©-entra√Æn√© (Transfer Learning) comme  ResNet ou EfficientNet

-Ajouter des transformations dans la data augmentation (contraste, luminosit√©, cisaillement (visage inclin√©), bruit)

-Entra√Æner plus longtemps avec Early Stopping : le mod√®le a √©t√© entra√Æn√© sur
15 epochs ce qui peut √™tre insuffisant donc ajouter un EarlyStopping pour √©viter le sur-apprentissage et augmenter le nombre d'epochs

-Ajouter un Dropout (0.3-0.5) dans la partie dense

-Ajouter une r√©gularisation L2 sur la derni√®re couche dense pour √©viter que le mod√®le s'ajuste trop aux donn√©es d'entra√Ænement

D√©cision pour la suite :

-Ajout d'une 4e couche de convolution avec 256 filtres
pour tenter d'extraire des caract√©ristiques plus complexes

-Apprentissage de ces caract√©ristiques complexes par une couche layer Dense avec 256 neurones

-Ajout d'une fonction Early Stopping permettant l'arr√™t pr√©matur√© de l'entra√Ænement si pas de progr√®s significatif sur mae et val_mae

-Ajuster dynamiquement le taux d'apprentissage pendant l'entra√Ænement pour aider le mod√®le √† converger vers un meilleur pouvoir de pr√©diction







"""

# Installation de google drive
from google.colab import drive
drive.mount('/content/drive')

# Essai am√©lioration du mod√®le de r√©gression
# chargement des biblioth√®ques
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, Callback
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Chargement et exploration des donn√©es
data_dir = "/content/drive/MyDrive/utkcropped"
file_paths = []
ages = []

for file in os.listdir(data_dir):
    if file.endswith(".jpg"):
        age = int(file.split("_")[0])
        file_paths.append(os.path.join(data_dir, file))
        ages.append(age)

# Pr√©paration des donn√©es
img_height, img_width = 200, 200
batch_size = 32

def gaussian_blur(image):
    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.02)  # Ajout de bruit l√©ger
    return tf.clip_by_value(image + noise, 0.0, 1.0)  # Garde les valeurs entre [0,1]

def process_image(file_path, label):
    img = tf.io.read_file(file_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width]) / 255.0

    #img = gaussian_blur(img)  # üîπ Ajout du flou (bruit gaussien l√©ger)

    return img, label

# Cr√©ation d'un DataFrame
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

df = pd.DataFrame({"file_path": file_paths, "age": ages})
df.head()

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age"], test_size=0.2, random_state=42)

train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

data_augmentation = Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1)
])

# Essai am√©lioration Mod√®le CNN pour la r√©gression (pr√©diction d'√¢ge)
model5_regression = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Conv2D(256, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),

    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(1)
])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

model5_regression.compile(optimizer='adam', loss='mse', metrics=['mae'])

# D√©finir le callback ReduceLROnPlateau (ajustement dynamique du taux d'apprentissage)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',  # Surveiller la perte de validation
    factor=0.5,          # R√©duire le taux d'apprentissage par un facteur de 0.5
    patience=5,          # Nombre d'epochs sans am√©lioration avant de r√©duire le taux d'apprentissage
    verbose=1            # Afficher un message lorsqu'il y a r√©duction du taux d'apprentissage
)

# Entra√Ænement

# Fichiers pour sauvegarder les poids et l'√©tat des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model5_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_epoch5_checkpoint.txt'

# D√©finir un callback personnalis√© pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch termin√©e (epoch commence √† 0)

# V√©rifier si un checkpoint existe d√©j√† et r√©cup√©rer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegard√©s...")
    model5_regression.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch d√©j√† faite
        print(f"Reprise √† l'epoch {initial_epoch}")

# D√©finir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entra√Ænement en ne faisant que les epochs restantes
total_epochs = 30  # Nombre total d'epochs pr√©vu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entra√Ænement pour {remaining_epochs} epochs restantes...")
    history_reg5 = model5_regression.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistr√©e
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver, reduce_lr, early_stopping])

    # Sauvegarde du mod√®le complet apr√®s l'entra√Ænement
    model5_regression.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model5.h5')
    print("Mod√®le final sauvegard√© sous viken_bloc4_cdsd_m2i_age_detection_model5.h5")

else:
    print("Entra√Ænement d√©j√† termin√© !")

# √âvaluation
y_pred_reg5 = model5_regression.predict(test_data).flatten()

mae5 = np.mean(np.abs(y_pred_reg5 - y_test))

# Affichage des r√©sultats
print(f"MAE (R√©gression) : {mae5}")

# R√©cup√©rer les valeurs de loss et MAE depuis l'entra√Ænement
loss5 = history_reg5.history['loss']
val_loss5 = history_reg5.history['val_loss']
mae5 = history_reg5.history['mae']
val_mae5 = history_reg5.history['val_mae']

# Tracer les courbes de loss et MAE
# Tracer les courbes de loss et MAE
plt.figure(figsize=(12, 6))

# Courbes de Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, 31), loss5, label="Training Loss")
plt.plot(range(1, 31), val_loss5, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - r√©gression pr√©dire √¢ge')
plt.legend()

# Courbes de MAE (Mean Absolute Error)
plt.subplot(1, 2, 2)
plt.plot(range(1, 31), mae5, label="Training MAE")
plt.plot(range(1, 31), val_mae5, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Training and Validation MAE - r√©gression pr√©dire √¢ge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()

"""Avant la diminution dynamique du taux d'apprentissage √† la 19e epoch, le mod√®le fait des sauts trop brusques dans la descente de gradient, ce qui cause des oscillations (0,001 appara√Æt donc comme un taux d'apprentissage trop grand).
Le passage de ce taux √† 5e-4 diminue significativement ces oscillations ce qui aide le mod√®le √† converger vers un meilleur pouvoir de pr√©diction.

"""

# Tracer les courbes de loss et MAE pour l'entra√Ænement et la validation
plt.figure(figsize=(12, 6))

# Loss et MAE pour l'entra√Ænement
plt.subplot(1, 2, 1)
# Courbe de Loss pour l'entra√Ænement
plt.plot(range(1, 31), loss5, label="Training Loss")  # Plage ajust√©e √† 30 epochs
# Courbe de MAE pour l'entra√Ænement
plt.plot(range(1, 31), mae5, label="Training MAE")  # Plage ajust√©e √† 30 epochs
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Training Loss & MAE - r√©gression pr√©dire √¢ge')
plt.legend()

# Loss et MAE pour la validation
plt.subplot(1, 2, 2)  # 1 ligne, 2 colonnes, deuxi√®me vignette
# Courbe de Loss pour la validation
plt.plot(range(1, 31), val_loss5, label="Validation Loss")  # Plage ajust√©e √† 30 epochs
# Courbe de MAE pour la validation
plt.plot(range(1, 31), val_mae5, label="Validation MAE")  # Plage ajust√©e √† 30 epochs
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Validation Loss & MAE - r√©gression pr√©dire √¢ge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Essai mod√®le 2
import os
import random
import tensorflow as tf
import matplotlib.pyplot as plt

# Chemin du dossier contenant les images du dataset n'ayant ni particip√© √† l'entra√Ænement ni particip√© au test du mod√®le de d√©tection de l'√¢ge
test_folder = "drive/MyDrive/utkcroppedpredict"

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# V√©rifier s'il y a des images dans le dossier
if not image_files:
    print("Aucune image trouv√©e dans le dossier !")
else:
    # S√©lectionner un fichier image au hasard
    random_file = random.choice(image_files)
    file_path = os.path.join(test_folder, random_file)

    # Extraire l'√¢ge r√©el √† partir du nom du fichier (avant le premier "_")
    real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

    # Charger et pr√©traiter l'image
    image, _ = process_image(file_path, real_age)  # Passer l'√¢ge r√©el pour affichage si n√©cessaire

    # Affichage de l'image
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.axis('off')

    # Pr√©dire l'√¢ge avec le mod√®le
    predicted_age = model5_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

    # Afficher l'√¢ge r√©el et l'√¢ge pr√©dit
    plt.title(f"√Çge r√©el: {real_age}, √Çge pr√©dit: {predicted_age:.2f}")
    plt.show()

# Nombre d'images √† afficher
num_images = 5

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# V√©rifier s'il y a suffisamment d'images dans le dossier
if len(image_files) < num_images:
    print(f"Seulement {len(image_files)} images disponibles, ajustez `num_images`.")
else:
    # Cr√©er une figure pour afficher les images
    plt.figure(figsize=(15, 15))

    # S√©lectionner et afficher plusieurs images al√©atoires
    for i in range(num_images):
        # S√©lectionner un fichier image au hasard
        random_file = random.choice(image_files)
        file_path = os.path.join(test_folder, random_file)

        # Extraire l'√¢ge r√©el √† partir du nom du fichier (avant le premier "_")
        real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

        # Charger et pr√©traiter l'image
        image, _ = process_image(file_path, real_age)  # Passer l'√¢ge r√©el pour affichage si n√©cessaire

        # Pr√©dire l'√¢ge de l'image avec le mod√®le de r√©gression
        predicted_age = model5_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

        # Afficher l'image dans un sous-graphe (m√©daillon)
        plt.subplot(1, num_images, i + 1)  # 1 ligne et 'num_images' colonnes
        plt.imshow(image)
        plt.axis('off')

        # Afficher l'√¢ge r√©el et pr√©dit sur l'image
        plt.title(f"R√©el: {real_age}, Pr√©dit: {predicted_age:.2f}")

    # Affichage de toutes les images
    plt.tight_layout()
    plt.show()

# Essai pr√©diction d'√¢ge avec photo nouvelle
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
from tensorflow.keras.losses import MeanSquaredError

model = load_model('/content/drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model5.h5',
                   custom_objects={'mse': MeanSquaredError()})  # Corrige l'erreur de 'mse'

print("Mod√®le charg√© avec succ√®s !")

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de pr√©traitement pour une image
def process_image(image_path, target_size=(200, 200)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
    img_resized = cv2.resize(img, target_size)  # Redimensionner
    img_array = np.expand_dims(img_resized, axis=0) / 255.0  # Ajouter batch & normaliser
    return img_array, img_resized  # Retourne aussi l'image redimensionn√©e pour affichage

# Chemins des trois images
image_path1 = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace par ton chemin
image_path2 = '/content/drive/MyDrive/VikMaIMG-20250308-WA0000.jpg'  # Remplace par ton chemin
image_path3 = '/content/drive/MyDrive/VikPaIMG-20250308-WA0001.jpg'  # Remplace par ton chemin

# Charger les images
image_array1, img_resized1 = process_image(image_path1)
image_array2, img_resized2 = process_image(image_path2)
image_array3, img_resized3 = process_image(image_path3)

# Pr√©dire les √¢ges
predicted_age1 = model.predict(image_array1).flatten()[0]
predicted_age2 = model.predict(image_array2).flatten()[0]
predicted_age3 = model.predict(image_array3).flatten()[0]

# Afficher les images avec les √¢ges pr√©dits
fig, axes = plt.subplots(1, 3, figsize=(20, 5))  # 3 images en ligne

axes[0].imshow(img_resized1)
axes[0].axis('off')
axes[0].set_title(f"√Çge pr√©dit : {predicted_age1:.2f}")

axes[1].imshow(img_resized2)
axes[1].axis('off')
axes[1].set_title(f"√Çge pr√©dit : {predicted_age2:.2f}")

axes[2].imshow(img_resized3)
axes[2].axis('off')
axes[2].set_title(f"√Çge pr√©dit : {predicted_age3:.2f}")

plt.show()

