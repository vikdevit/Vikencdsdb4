# -*- coding: utf-8 -*-
"""VikenBloc4CDSDm2icGAN_40epochs_courbe.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ingIFf_xlIzI4htWXGJLYv2V-XVYd24
"""

from google.colab import drive
drive.mount('/content/drive')  # Monte Google Drive vikenvik9@gmail.com

# installer les dépendances
! pip install torch torchvision numpy matplotlib pillow

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from torchvision.utils import save_image
import os
from PIL import Image
import glob
import matplotlib.pyplot as plt
import numpy as np

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
batch_size = 64
epochs = 40
lr = 0.0002
image_size = 128
latent_dim = 100
age_threshold = 30  # Seuil d'âge pour considérer une image comme "jeune"

# Chemin vers UTKFace
dataset_path = "/content/drive/MyDrive/utkcropped"

# Définition du Dataset UTKFace (sélectionne uniquement les jeunes)
class UTKFaceDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.image_paths = [p for p in glob.glob(os.path.join(root_dir, "*.jpg"))
                            if int(os.path.basename(p).split("_")[0]) <= age_threshold]
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        return image

# Transformations
transform = transforms.Compose([
    transforms.Resize((image_size, image_size)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Charger dataset
dataset = UTKFaceDataset(dataset_path, transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Générateur du cGAN
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim + 1, 256),  # Ajout d'une condition d'âge
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, image_size * image_size * 3),
            nn.Tanh()
        )

    def forward(self, z, age_label):
        age_label = age_label.view(-1, 1)  # Ajoute une dimension
        input_vector = torch.cat((z, age_label), dim=1)  # Concatène bruit et condition
        img = self.model(input_vector)
        img = img.view(img.size(0), 3, image_size, image_size)
        return img

# Discriminateur du cGAN
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(image_size * image_size * 3 + 1, 1024),  # Ajout d'une condition d'âge
            nn.LeakyReLU(0.2),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, img, age_label):
        img_flat = img.view(img.size(0), -1)
        age_label = age_label.view(-1, 1)
        input_vector = torch.cat((img_flat, age_label), dim=1)  # Concatène image et condition
        return self.model(input_vector)

# Initialisation
generator = Generator().to(device)
discriminator = Discriminator().to(device)
criterion = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

# Listes pour suivre les pertes du générateur et du discriminateur
d_losses = []
g_losses = []

# Entraînement du cGAN
for epoch in range(epochs):
    for i, imgs in enumerate(dataloader):
        real_imgs = imgs.to(device)
        batch_size = real_imgs.size(0)

        # Labels réels et faux
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Générer un âge cible aléatoire (ex: entre 40 et 100 ans)
        target_ages = torch.randint(40, 101, (batch_size,)).float().to(device) / 100.0

        # Entraîner Discriminateur
        z = torch.randn(batch_size, latent_dim).to(device)
        fake_imgs = generator(z, target_ages)

        real_loss = criterion(discriminator(real_imgs, target_ages), real_labels)
        fake_loss = criterion(discriminator(fake_imgs.detach(), target_ages), fake_labels)
        d_loss = real_loss + fake_loss

        optimizer_D.zero_grad()
        d_loss.backward()
        optimizer_D.step()

        # Entraîner Générateur
        g_loss = criterion(discriminator(fake_imgs, target_ages), real_labels)

        optimizer_G.zero_grad()
        g_loss.backward()
        optimizer_G.step()

        # Stocker les pertes pour analyse
        d_losses.append(d_loss.item())
        g_losses.append(g_loss.item())

        # **Afficher la progression toutes les 100 itérations**
        if i % 100 == 0:
            print(f"Epoch [{epoch}/{epochs}], Batch [{i}/{len(dataloader)}] - "
                  f"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}")

            # **Détection de l'effondrement du GAN**
            if d_loss.item() < 0.1:
                print("Attention : le discriminateur devient trop fort ! Ajuste le learning rate ou ajoute du bruit.")

    # **Sauvegarde et affichage des images générées tous les 10 epochs**
    if epoch % 10 == 0:
        save_image(fake_imgs[:25], f"/content/drive/MyDrive/progress_epoch_{epoch}.png", nrow=5, normalize=True)
        print(f"Images sauvegardées : progress_epoch_{epoch}.png")

        # **Afficher une image générée**
        img = fake_imgs[0].cpu().detach().numpy()  # Convertir en numpy
        img = np.transpose(img, (1, 2, 0))  # Repasser en format image (H, W, C)
        img = (img + 1) / 2  # Dé-normaliser pour avoir des valeurs entre 0 et 1

        plt.imshow(img)
        plt.axis("off")
        plt.title(f"Image générée - Epoch {epoch}")
        plt.show()

# **Tracer l'évolution des pertes après l'entraînement**
plt.plot(d_losses, label="Discriminator Loss", alpha=0.7)
plt.plot(g_losses, label="Generator Loss", alpha=0.7)
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.legend()
plt.title("Évolution des pertes du GAN")
plt.savefig("/content/drive/MyDrive/training_loss_plot.png")
plt.show()

print("Entraînement terminé !")

# Sauvegarde du modèle
torch.save(generator.state_dict(), "/content/drive/MyDrive/face_aging_cgan.pth")

























