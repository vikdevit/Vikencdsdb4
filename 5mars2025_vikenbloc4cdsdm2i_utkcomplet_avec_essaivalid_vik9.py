# -*- coding: utf-8 -*-
"""5Mars2025_VikenBloc4CDSDM2i_utkcomplet_vik9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14yo-_WTIXRg6OzFK3Fb2goKy1uMAHdj1
"""

# Installation de google drive
from google.colab import drive
drive.mount('/content/drive')

# chargement des bibliothèques
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, Callback
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Chargement et exploration des données
data_dir = "/content/drive/MyDrive/utkcropped"
file_paths = []
ages = []

for file in os.listdir(data_dir):
    if file.endswith(".jpg"):
        age = int(file.split("_")[0])
        file_paths.append(os.path.join(data_dir, file))
        ages.append(age)

# Création d'un DataFrame
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

df = pd.DataFrame({"file_path": file_paths, "age": ages})
df.head()

# affichage du nombre de lignes et de colonnes du dataframe
df.shape

# Visualisation de la distribution des âges
plt.figure(figsize=(10, 6))
sns.histplot(df["age"], bins=30, kde=True)
plt.title("Distribution des âges dans UTKFace")
plt.show()

# Violin plot
plt.figure(figsize=(10, 6))
sns.violinplot(y=df["age"])
plt.title("Répartition des âges")
plt.show()

df.describe()

# Préparation des données
img_height, img_width = 200, 200
batch_size = 32

def process_image(file_path, label):
    img = tf.io.read_file(file_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [img_height, img_width]) / 255.0
    return img, label

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age"], test_size=0.2, random_state=42)

train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

# Data Augmentation
data_augmentation = Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

# Modèle CNN pour la régression (prédiction d'âge)
model_regression = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(1)
])

model_regression.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Entraînement

# Fichiers pour sauvegarder les poids et l'état des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_epoch_checkpoint.txt'

# Définir un callback personnalisé pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch terminée (epoch commence à 0)

# Vérifier si un checkpoint existe déjà et récupérer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegardés...")
    model_regression.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch déjà faite
        print(f"Reprise à l'epoch {initial_epoch}")

# Définir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entraînement en ne faisant que les epochs restantes
total_epochs = 15  # Nombre total d'epochs prévu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entraînement pour {remaining_epochs} epochs restantes...")
    history_reg = model_regression.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistrée
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver])

    # Sauvegarde du modèle complet après l'entraînement
    model_regression.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model.h5')
    print("Modèle final sauvegardé sous viken_bloc4_cdsd_m2i_age_detection_model.h5")

else:
    print("Entraînement déjà terminé !")

# Modèle CNN pour la classification par classes d'âge
bins = [0, 10, 20, 30, 40, 60, 80, np.inf]
labels = [0, 1, 2, 3, 4, 5, 6]
df["age_group"] = pd.cut(df["age"], bins=bins, labels=labels)

X_train, X_test, y_train, y_test = train_test_split(df["file_path"], df["age_group"].astype(int), test_size=0.2, random_state=42)
train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(process_image).batch(batch_size)
test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_image).batch(batch_size)

model_classification = Sequential([
    layers.InputLayer(input_shape=(img_height, img_width, 3)),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(len(labels), activation='softmax')
])

model_classification.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Entraînement

# Fichiers pour sauvegarder les poids et l'état des epochs
checkpoint_path = "drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_model_checkpoint.weights.h5"
epoch_file = 'drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_epoch_checkpoint.txt'

# Définir un callback personnalisé pour sauvegarder l'epoch actuelle
class EpochSaver(Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(epoch_file, 'w') as f:
            f.write(str(epoch + 1))  # Sauvegarde l'epoch terminée (epoch commence à 0)

# Vérifier si un checkpoint existe déjà et récupérer l'epoch actuelle
initial_epoch = 0
if os.path.exists(checkpoint_path):
    print("Chargement des poids sauvegardés...")
    model_classification.load_weights(checkpoint_path)

    if os.path.exists(epoch_file):
        with open(epoch_file, 'r') as f:
            initial_epoch = int(f.read())  # Lire l'epoch déjà faite
        print(f"Reprise à l'epoch {initial_epoch}")

# Définir les callbacks (ModelCheckpoint + EpochSaver)
checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=False, save_weights_only=True, verbose=1)
epoch_saver = EpochSaver()

# Reprendre l'entraînement en ne faisant que les epochs restantes
total_epochs = 15  # Nombre total d'epochs prévu
remaining_epochs = total_epochs - initial_epoch

if remaining_epochs > 0:
    print(f"Reprise de l'entraînement pour {remaining_epochs} epochs restantes...")
    history_class = model_classification.fit(train_data, validation_data=test_data,
              initial_epoch=initial_epoch,  # Reprise de l'epoch enregistrée
              epochs=total_epochs,
              batch_size=32,
              callbacks=[checkpoint, epoch_saver])

    # Sauvegarde du modèle complet après l'entraînement
    model_classification.save('drive/MyDrive/viken_bloc4_cdsd_m2i_age_classification_model.h5')
    print("Modèle final sauvegardé sous viken_bloc4_cdsd_m2i_age_classification_model.h5")

else:
    print("Entraînement déjà terminé !")

# Évaluation
y_pred_reg = model_regression.predict(test_data).flatten()
y_pred_class = np.argmax(model_classification.predict(test_data), axis=1)

mae = np.mean(np.abs(y_pred_reg - y_test))
accuracy = accuracy_score(y_test, y_pred_class)
precision = precision_score(y_test, y_pred_class, average='weighted')
recall = recall_score(y_test, y_pred_class, average='weighted')
f1 = f1_score(y_test, y_pred_class, average='weighted')
cm = confusion_matrix(y_test, y_pred_class)

# Affichage des résultats
print(f"MAE (Régression) : {mae}")
print(f"Accuracy (Classification) : {accuracy}")
print(f"Precision : {precision}")
print(f"Recall : {recall}")
print(f"F1-score : {f1}")
print("Matrice de confusion :\n", cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Prédit")
plt.ylabel("Réel")
plt.show()

# Affichage de la heatmap avec les bonnes étiquettes pour les classes
plt.figure(figsize=(8, 6))

# Remplacer les étiquettes par les tranches d'âge dans la matrice de confusion
age_groups = ['0-10', '10-20', '20-30', '30-40', '40-60', '60-80', '80+']  # Correspond aux labels des bins

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=age_groups, yticklabels=age_groups)

plt.xlabel("Âge Prédit (an(s))")
plt.ylabel("Âge Réel (an(s))")
plt.title("Matrice de Confusion avec Tranches d'Âge")
plt.show()

# Récupérer les valeurs de loss et MAE depuis l'entraînement
loss = history_reg.history['loss']
val_loss = history_reg.history['val_loss']
mae = history_reg.history['mae']
val_mae = history_reg.history['val_mae']

# Tracer les courbes de loss et MAE
plt.figure(figsize=(12, 6))

# Courbes de Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, 16), loss, label="Training Loss")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - régession prédire âge')
plt.legend()

# Courbes de MAE (Mean Absolute Error)
plt.subplot(1, 2, 2)
plt.plot(range(1, 16), mae, label="Training MAE")
plt.plot(range(1, 16), val_mae, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Training and Validation MAE - régression prédire âge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Tracer les courbes de loss et MAE pour l'entraînement et la validation
plt.figure(figsize=(12, 6))

# Loss et MAE pour l'entraînement
plt.subplot(1, 2, 1)
# Courbe de Loss pour l'entraînement
plt.plot(range(1, 16), loss, label="Training Loss")
# Courbe de MAE pour l'entraînement
plt.plot(range(1, 16), mae, label="Training MAE")
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Training Loss & MAE - régression prédire âge')
plt.legend()

# Loss et MAE pour la validation
plt.subplot(1, 2, 2)  # 1 ligne, 2 colonnes, deuxième vignette
# Courbe de Loss pour la validation
plt.plot(range(1, 16), val_loss, label="Validation Loss")
# Courbe de MAE pour la validation
plt.plot(range(1, 16), val_mae, label="Validation MAE")
plt.xlabel('Epochs')
plt.ylabel('Loss / MAE')
plt.title('Validation Loss & MAE - régression prédire âge')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Récupération des données d'accuracy et de loss (classification multi-classes)
acc = history_class.history['accuracy']
val_acc = history_class.history['val_accuracy']
loss = history_class.history['loss']
val_loss = history_class.history['val_loss']

# Tracer les courbes de comparaison de l'accuracy et de loss entre training et validation (test)
plt.figure(figsize=(12, 6))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(range(1, 16), acc, label="Training Accuracy")
plt.plot(range(1, 16), val_acc, label="Validation Accuracy")
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy - classification âge multi-classes')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(range(1, 16), loss, label="Training Loss")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss - classification âge multi-classes')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

# Tracer pour chacun des ensembles d'entraînement et de test les courbes de l'accuracy et de loss
plt.figure(figsize=(24, 6))  # Augmenter la largeur pour accueillir 4 subplots

# Training Accuracy and Loss
plt.subplot(1, 4, 3)  # 1 ligne, 4 colonnes, 3e subplot
plt.plot(range(1, 16), acc, label="Accuracy")
plt.plot(range(1, 16), loss, label="Loss")
plt.xlabel('Epochs')
plt.title('Training Accuracy and Loss - classification âge multi-classes')
plt.legend()

# Validation Accuracy and Loss
plt.subplot(1, 4, 4)  # 1 ligne, 4 colonnes, 4e subplot
plt.plot(range(1, 16), val_acc, label="Validation Accuracy")
plt.plot(range(1, 16), val_loss, label="Validation Loss")
plt.xlabel('Epochs')
plt.ylabel('Metrics')
plt.title('Validation Accuracy and Loss - classification âge multi-classes')
plt.legend()

# Affichage des graphiques
plt.tight_layout()
plt.show()

import os
import random
import tensorflow as tf
import matplotlib.pyplot as plt

# Chemin du dossier contenant les images du dataset n'ayant ni participé à l'entraînement ni participé au test du modèle de détection de l'âge
test_folder = "drive/MyDrive/utkcroppedpredict"

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# Vérifier s'il y a des images dans le dossier
if not image_files:
    print("Aucune image trouvée dans le dossier !")
else:
    # Sélectionner un fichier image au hasard
    random_file = random.choice(image_files)
    file_path = os.path.join(test_folder, random_file)

    # Extraire l'âge réel à partir du nom du fichier (avant le premier "_")
    real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

    # Charger et prétraiter l'image
    image, _ = process_image(file_path, real_age)  # Passer l'âge réel pour affichage si nécessaire

    # Affichage de l'image
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.axis('off')

    # Prédire l'âge avec le modèle
    predicted_age = model_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

    # Afficher l'âge réel et l'âge prédit
    plt.title(f"Âge réel: {real_age}, Âge prédit: {predicted_age:.2f}")
    plt.show()

# Nombre d'images à afficher
num_images = 5

# Lister tous les fichiers d'images dans le dossier
image_files = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png', '.jpeg', '.chip'))]

# Vérifier s'il y a suffisamment d'images dans le dossier
if len(image_files) < num_images:
    print(f"Seulement {len(image_files)} images disponibles, ajustez `num_images`.")
else:
    # Créer une figure pour afficher les images
    plt.figure(figsize=(15, 15))

    # Sélectionner et afficher plusieurs images aléatoires
    for i in range(num_images):
        # Sélectionner un fichier image au hasard
        random_file = random.choice(image_files)
        file_path = os.path.join(test_folder, random_file)

        # Extraire l'âge réel à partir du nom du fichier (avant le premier "_")
        real_age = int(random_file.split("_")[0])  # Prend la partie avant le premier "_"

        # Charger et prétraiter l'image
        image, _ = process_image(file_path, real_age)  # Passer l'âge réel pour affichage si nécessaire

        # Prédire l'âge de l'image avec le modèle de régression
        predicted_age = model_regression.predict(tf.expand_dims(image, axis=0)).flatten()[0]

        # Afficher l'image dans un sous-graphe (médaillon)
        plt.subplot(1, num_images, i + 1)  # 1 ligne et 'num_images' colonnes
        plt.imshow(image)
        plt.axis('off')

        # Afficher l'âge réel et prédit sur l'image
        plt.title(f"Réel: {real_age}, Prédit: {predicted_age:.2f}")

    # Affichage de toutes les images
    plt.tight_layout()
    plt.show()

# Essai prédiction d'âge avec photo nouvelle
from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
from tensorflow.keras.losses import MeanSquaredError

model = load_model('/content/drive/MyDrive/viken_bloc4_cdsd_m2i_age_detection_model.h5',
                   custom_objects={'mse': MeanSquaredError()})  # Corrige l'erreur de 'mse'

print("Modèle chargé avec succès !")

# Essai prédiction d'âge avec photo nouvelle
import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de prétraitement pour l'image (en tenant compte de la taille de 200x200)
def process_image(image_path, target_size=(200, 200)):
    # Charger l'image avec OpenCV
    img = cv2.imread(image_path)

    # Convertir l'image en RGB (OpenCV charge par défaut en BGR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Redimensionner l'image à la taille que le modèle attend
    img_resized = cv2.resize(img, target_size)

    # Normaliser l'image (par exemple, normalisation entre 0 et 1)
    img_array = np.expand_dims(img_resized, axis=0)  # Ajouter la dimension du batch
    img_array = img_array / 255.0  # Normaliser les pixels entre 0 et 1

    return img_array

# Chemin du fichier de l'image à prédire
img_path = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace avec le chemin de ton image

# Appliquer le prétraitement à l'image
image_array = process_image(img_path)

# Charger le modèle (si non chargé encore, assure-toi qu'il est déjà chargé et entraîné)
# model_regression = tf.keras.models.load_model('path_to_your_model')  # Si tu n'as pas déjà chargé le modèle

# Prédiction de l'âge avec le modèle
predicted_age = model.predict(image_array).flatten()[0]

# Afficher l'image et l'âge prédit
img = cv2.imread(img_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB pour affichage
plt.imshow(img)
plt.axis('off')
plt.title(f"Âge prédit : {predicted_age:.2f}")
plt.show()

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de prétraitement pour une image
def process_image(image_path, target_size=(200, 200)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
    img_resized = cv2.resize(img, target_size)  # Redimensionner
    img_array = np.expand_dims(img_resized, axis=0) / 255.0  # Ajouter batch & normaliser
    return img_array, img_resized  # Retourne aussi l'image redimensionnée pour affichage

# Chemins des deux images
image_path1 = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace par ton chemin
image_path2 = '/content/drive/MyDrive/VikMaIMG-20250308-WA0000.jpg'  # Remplace par ton chemin

# Charger les images
image_array1, img_resized1 = process_image(image_path1)
image_array2, img_resized2 = process_image(image_path2)

# Prédire les âges
predicted_age1 = model.predict(image_array1).flatten()[0]
predicted_age2 = model.predict(image_array2).flatten()[0]

# Afficher les images avec les âges prédits
fig, axes = plt.subplots(1, 2, figsize=(10, 5))
axes[0].imshow(img_resized1)
axes[0].axis('off')
axes[0].set_title(f"Âge prédit : {predicted_age1:.2f}")

axes[1].imshow(img_resized2)
axes[1].axis('off')
axes[1].set_title(f"Âge prédit : {predicted_age2:.2f}")

plt.show()

import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Fonction de prétraitement pour une image
def process_image(image_path, target_size=(200, 200)):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
    img_resized = cv2.resize(img, target_size)  # Redimensionner
    img_array = np.expand_dims(img_resized, axis=0) / 255.0  # Ajouter batch & normaliser
    return img_array, img_resized  # Retourne aussi l'image redimensionnée pour affichage

# Chemins des trois images
image_path1 = '/content/drive/MyDrive/Viken_photmorning.jpg'  # Remplace par ton chemin
image_path2 = '/content/drive/MyDrive/VikMaIMG-20250308-WA0000.jpg'  # Remplace par ton chemin
image_path3 = '/content/drive/MyDrive/VikPaIMG-20250308-WA0001.jpg'  # Remplace par ton chemin
image_path4 = '/content/drive/MyDrive/photo_5ans.jpg'

# Charger les images
image_array1, img_resized1 = process_image(image_path1)
image_array2, img_resized2 = process_image(image_path2)
image_array3, img_resized3 = process_image(image_path3)
image_array4, img_resized4 = process_image(image_path4)

# Prédire les âges
predicted_age1 = model.predict(image_array1).flatten()[0]
predicted_age2 = model.predict(image_array2).flatten()[0]
predicted_age3 = model.predict(image_array3).flatten()[0]
predicted_age4 = model.predict(image_array4).flatten()[0]

# Afficher les images avec les âges prédits
fig, axes = plt.subplots(1, 4, figsize=(20, 5))  # 3 images en ligne

axes[0].imshow(img_resized1)
axes[0].axis('off')
axes[0].set_title(f"Âge prédit : {predicted_age1:.2f}")

axes[1].imshow(img_resized2)
axes[1].axis('off')
axes[1].set_title(f"Âge prédit : {predicted_age2:.2f}")

axes[2].imshow(img_resized3)
axes[2].axis('off')
axes[2].set_title(f"Âge prédit : {predicted_age3:.2f}")

axes[3].imshow(img_resized4)
axes[3].axis('off')
axes[3].set_title(f"Âge prédit : {predicted_age4:.2f}")

plt.show()

""" Le modèle fonctionne correctement sur UTKFace mais mal sur d’autres images, ce qui suggère un problème de généralisation.

 Causes possibles :

-Erreur moyenne élevée
mae (mean absolute error) = 7.98 ans sur l'entraînement
val_mae = 8.59 ans sur la validation
Le modèle a en moyenne 8 ans d'écart entre l'âge réel et prédit. Il peut donc faire des erreurs importantes sur des images hors distribution.

-Sur-apprentissage possible
La loss d'entraînement est plus basse que la loss de validation.
Cela peut indiquer un sur-apprentissage en ce sens que le modèle s’adapte trop aux images UTKFace mais ne généralise pas bien.

Solutions possibles:

-Ajouter d'autres bases de données d'images contenant plus de diversité.

-Essayer un modèle pré-entraîné (Transfer Learning) comme  ResNet ou EfficientNet

-Améliorer la fonction de perte : la MAE est plus robuste pour les prédicitons d'âge car elle punit moins les grosses erreurs que la MSE, ce qui est utile pour éviter des erreurs massives sur certaines images.

-Entraîner plus longtemps avec Early Stopping : le modèle a été entraîné sur
15 epochs ce qui peut être insuffisant donc ajouter un EarlyStopping pour éviter le sur-apprentissage et augmenter le nombre d'epochs

-Décision d'utiliser le transfer learning avec fine tuning:
Utiliser un modèle pré-entraîné (comme ResNet ou EfficientNet) qui a déjà appris à détecter des formes et des textures sur des millions d’images (ImageNet). On réutilise ces connaissances et on ajuste juste la dernière partie du réseau pour qu'il apprenne à prédire l'âge.
Débloquer certaines couches et fine-tuner le modèle : Entraînement plus long (peut prendre plusieurs heures), permet d’adapter mieux le modèle à ton jeu de données

"""

# Préparer les données UTKFace
import tensorflow as tf
import numpy as np
import os
import cv2

# Chemin du dataset UTKFace
dataset_path = "/content/drive/MyDrive/utkcropped"

# Fonction pour extraire l'âge depuis le nom du fichier
def extract_age(filename):
    return int(filename.split("_")[0])

# Préparer les données
img_size = (200, 200)  # Taille pour EfficientNet
X, y = [], []

for file in os.listdir(dataset_path):
    if file.endswith(".jpg"):  # Vérifier que c'est bien une image
        img = cv2.imread(os.path.join(dataset_path, file))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir en RGB
        img = cv2.resize(img, img_size)  # Redimensionner
        X.append(img)
        y.append(extract_age(file))  # Extraire l'âge

# Convertir en tableaux numpy
X = np.array(X) / 255.0  # Normalisation
y = np.array(y)

# Division en train / test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Charger EfficientNetB0 & ajouter les couches
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras import layers, models

# Charger EfficientNetB0 (sans la dernière couche)
base_model = EfficientNetB0(include_top=False, input_shape=(200, 200, 3), weights='imagenet')

# Geler certaines couches pour ne pas tout réentraîner
for layer in base_model.layers[:100]:  # On gèle les 100 premières couches
    layer.trainable = False

# Définir le nouveau modèle
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.BatchNormalization(),
    layers.Dense(1)  # Prédiction d'âge
])

# Compilation du modèle
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mae', metrics=['mae'])

# Afficher l’architecture
model.summary()

# Entraîner le modèle
# Fichier CSV pour sauvegarder les métriques
metrics_file = "/content/drive/MyDrive/efficientnet_utkface_metrics.csv"
with open(metrics_file, mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["Epoch", "Train_Loss", "Train_MAE", "Val_Loss", "Val_MAE"])

# Callback pour enregistrer les métriques après chaque epoch
class MetricsLogger(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        with open(metrics_file, mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([epoch + 1, logs["loss"], logs["mae"], logs["val_loss"], logs["val_mae"]])

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, callbacks=[MetricsLogger()])

# Sauvegarde du modèle après entraînement
model.save("/content/drive/MyDrive/efficientnet_utkface_age.h5")

# Charger les métriques enregistrées
metrics_data = pd.read_csv(metrics_file)

# Tracer la courbe de Loss
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(metrics_data["Epoch"], metrics_data["Train_Loss"], label="Train Loss")
plt.plot(metrics_data["Epoch"], metrics_data["Val_Loss"], label="Val Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Courbe de Loss")
plt.legend()

# Tracer la courbe de MAE
plt.subplot(1, 2, 2)
plt.plot(metrics_data["Epoch"], metrics_data["Train_MAE"], label="Train MAE")
plt.plot(metrics_data["Epoch"], metrics_data["Val_MAE"], label="Val MAE")
plt.xlabel("Epochs")
plt.ylabel("Mean Absolute Error (MAE)")
plt.title("Courbe de MAE")
plt.legend()

plt.show()

# Tester le modèle
# Fonction pour prédire l'âge d'une image
def predict_age(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (200, 200))
    img = np.expand_dims(img, axis=0) / 255.0  # Normalisation

    predicted_age = model.predict(img).flatten()[0]
    print(f"Âge prédit : {predicted_age:.2f}")

# Tester une image
test_image_path = "/content/drive/MyDrive/Viken_photmorning.jpg"  # Change le chemin
predict_age(test_image_path)