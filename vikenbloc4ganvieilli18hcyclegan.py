# -*- coding: utf-8 -*-
"""vikenbloc4GANvieilli18hcyclegan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y41xrmVHnRFQgF7ACmWGtFLJedI3U819
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import random

# Dataset personnalis√©
class SingleImageDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, image_path

# Transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Charger le dataset
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'
dataset = SingleImageDataset(image_dir, transform=transform)
random_idx = random.randint(0, len(dataset)-1)
real_image, image_path = dataset[random_idx]
real_image = real_image.unsqueeze(0)  # Ajout d'une dimension batch
print(f'Image choisie : {image_path}')

# Mod√®le G√©n√©rateur avec Dropout
class Generator(nn.Module):
    def __init__(self, input_channels, output_channels):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(input_channels, 64, 4, 2, 1), nn.ReLU(True), nn.Dropout(0.5),
            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(True), nn.Dropout(0.5),
            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU(True),
            nn.Conv2d(256, 512, 4, 2, 1), nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(True),
            nn.ConvTranspose2d(64, output_channels, 4, 2, 1), nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)

# Mod√®le Discriminateur
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1), nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1), nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1), nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 4, 2, 1), nn.LeakyReLU(0.2),
            nn.Flatten(),
            nn.Linear(512 * 8 * 8, 1), nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# Initialisation des mod√®les
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
generator_A_to_B = Generator(3, 3).to(device)
generator_B_to_A = Generator(3, 3).to(device)
discriminator_A = Discriminator().to(device)
discriminator_B = Discriminator().to(device)

# Optimisation et apprentissage
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(list(generator_A_to_B.parameters()) + list(generator_B_to_A.parameters()), lr=lr, betas=betas)
optimizer_D_A = optim.Adam(discriminator_A.parameters(), lr=lr, betas=betas)
optimizer_D_B = optim.Adam(discriminator_B.parameters(), lr=lr, betas=betas)

# Scheduler pour r√©duire le learning rate
scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=50, gamma=0.5)
scheduler_D_A = optim.lr_scheduler.StepLR(optimizer_D_A, step_size=50, gamma=0.5)
scheduler_D_B = optim.lr_scheduler.StepLR(optimizer_D_B, step_size=50, gamma=0.5)

# Crit√®res de perte
criterion_GAN = nn.MSELoss()
criterion_cycle = nn.L1Loss()
criterion_identity = nn.L1Loss()

# Listes pour tracer les pertes
G_losses = []
D_losses_A = []
D_losses_B = []

# Entra√Ænement
num_epochs = 300
for epoch in range(num_epochs):
    real_A = real_image.to(device)
    fake_B = generator_A_to_B(real_A)

    # Perte adversariale
    optimizer_G.zero_grad()
    pred_fake_A = discriminator_A(fake_B)
    loss_G_A = criterion_GAN(pred_fake_A, torch.ones_like(pred_fake_A).to(device))
    pred_fake_B = discriminator_B(real_A)
    loss_G_B = criterion_GAN(pred_fake_B, torch.ones_like(pred_fake_B).to(device))

    # Perte de cycle
    reconstructed_A = generator_B_to_A(fake_B)
    cycle_loss_A = criterion_cycle(reconstructed_A, real_A)
    reconstructed_B = generator_A_to_B(real_A)
    cycle_loss_B = criterion_cycle(reconstructed_B, fake_B)

    # Perte d'identit√©
    identity_loss_A = criterion_identity(generator_A_to_B(real_A), real_A)
    identity_loss_B = criterion_identity(generator_B_to_A(fake_B), fake_B)

    # Perte totale
    g_loss = loss_G_A + loss_G_B + cycle_loss_A + cycle_loss_B + 0.5 * (identity_loss_A + identity_loss_B)
    g_loss.backward()
    optimizer_G.step()

    # Mise √† jour des discriminateurs
    # Mise √† jour des discriminateurs
    # Optimisation de D_A
    optimizer_D_A.zero_grad()
    pred_real_A = discriminator_A(real_A)
    pred_fake_A = discriminator_A(fake_B.detach())  # D√©tach√© ici

    d_loss_A = criterion_GAN(pred_real_A, torch.ones_like(pred_real_A).to(device)) + \
               criterion_GAN(pred_fake_A, torch.zeros_like(pred_fake_A).to(device))

    d_loss_A.backward()  # Supprim√© retain_graph=True
    optimizer_D_A.step()

    # Optimisation de D_B
    optimizer_D_B.zero_grad()
    pred_real_B = discriminator_B(fake_B.detach())  # D√©tach√© ici
    pred_fake_B = discriminator_B(real_A.detach())  # D√©tach√© ici

    d_loss_B = criterion_GAN(pred_real_B, torch.ones_like(pred_real_B).to(device)) + \
               criterion_GAN(pred_fake_B, torch.zeros_like(pred_fake_B).to(device))

    d_loss_B.backward()  # Supprim√© retain_graph=True
    optimizer_D_B.step()


    # Stockage des pertes
    G_losses.append(g_loss.item())
    D_losses_A.append(d_loss_A.item())
    D_losses_B.append(d_loss_B.item())

    # Affichage tous les 10 epochs
    if epoch % 10 == 0:
        print(f'Epoch {epoch}/{num_epochs}, G Loss: {g_loss.item():.4f}, D Loss A: {d_loss_A.item():.4f}, D Loss B: {d_loss_B.item():.4f}')

# Affichage des courbes de perte
plt.plot(G_losses, label="Generator Loss")
plt.plot(D_losses_A, label="Discriminator A Loss")
plt.plot(D_losses_B, label="Discriminator B Loss")
plt.legend()
plt.show()

# ci-dessous premeire version cycle gan qui fonctionne
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import random

# ================================
# üìå 1. Chargement des images
# ================================
class SingleImageDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, image_path  # Retourne l'image et son chemin

# Transformations
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'
dataset = SingleImageDataset(image_dir, transform=transform)

# S√©lection d'une image al√©atoire
random_idx = random.randint(0, len(dataset)-1)
real_image, image_path = dataset[random_idx]
real_image = real_image.unsqueeze(0)  # Ajout de la dimension batch

print(f'üì∏ Image choisie : {image_path}')

# ================================
# üìå 2. D√©finition des mod√®les
# ================================
class Generator(nn.Module):
    def __init__(self, input_channels, output_channels):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(input_channels, 64, 4, 2, 1),
            nn.ReLU(True),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.ReLU(True),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.ReLU(True),
            nn.Conv2d(256, 512, 4, 2, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(512, 256, 4, 2, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(64, output_channels, 4, 2, 1),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten(),
            nn.Linear(512 * 8 * 8, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# ================================
# üìå 3. Initialisation des mod√®les
# ================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

generator_A_to_B = Generator(3, 3).to(device)
generator_B_to_A = Generator(3, 3).to(device)
discriminator_A = Discriminator().to(device)
discriminator_B = Discriminator().to(device)

# Optimiseurs
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(list(generator_A_to_B.parameters()) + list(generator_B_to_A.parameters()), lr=lr, betas=betas)
optimizer_D_A = optim.Adam(discriminator_A.parameters(), lr=lr, betas=betas)
optimizer_D_B = optim.Adam(discriminator_B.parameters(), lr=lr, betas=betas)

# Fonctions de perte
criterion_GAN = nn.MSELoss()
criterion_cycle = nn.L1Loss()

# ================================
# üìå 4. Fonction d'affichage
# ================================
def show_images(real_image, fake_image, epoch):
    real_image = real_image / 2 + 0.5  # D√©normalisation
    fake_image = fake_image / 2 + 0.5

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))

    axes[0].imshow(real_image.squeeze(0).permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title('Image r√©elle')
    axes[0].axis('off')

    axes[1].imshow(fake_image.squeeze(0).permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title('Image vieillie')
    axes[1].axis('off')

    plt.suptitle(f'Epoch {epoch+1}')
    plt.show()

# ================================
# üìå 5. Entra√Ænement
# ================================
num_epochs = 100
display_interval = 10

torch.autograd.set_detect_anomaly(True)  # Active la d√©tection des erreurs

for epoch in range(num_epochs):
    real_A = real_image.to(device)
    fake_B = generator_A_to_B(real_A)

    optimizer_G.zero_grad()
    pred_fake_A = discriminator_A(fake_B)
    loss_G_A = criterion_GAN(pred_fake_A, torch.ones_like(pred_fake_A).to(device))

    pred_fake_B = discriminator_B(real_A)
    loss_G_B = criterion_GAN(pred_fake_B, torch.ones_like(pred_fake_B).to(device))

    reconstructed_A = generator_B_to_A(fake_B)
    cycle_loss_A = criterion_cycle(reconstructed_A, real_A)

    g_loss = loss_G_A + loss_G_B + cycle_loss_A
    g_loss.backward()
    optimizer_G.step()

    # üéØ Mise √† jour des discriminateurs
    optimizer_D_A.zero_grad()
    pred_real_A = discriminator_A(real_A)
    pred_fake_A = discriminator_A(fake_B.detach())
    loss_real_A = criterion_GAN(pred_real_A, torch.ones_like(pred_real_A).to(device))
    loss_fake_A = criterion_GAN(pred_fake_A, torch.zeros_like(pred_fake_A).to(device))
    d_loss_A = loss_real_A + loss_fake_A
    d_loss_A.backward()
    optimizer_D_A.step()

    optimizer_D_B.zero_grad()
    pred_real_B = discriminator_B(fake_B.detach())  # Utilisation de .detach() pour √©viter de recalculer les gradients
    pred_fake_B = discriminator_B(real_A)

    loss_real_B = criterion_GAN(pred_real_B, torch.ones_like(pred_real_B).to(device))
    loss_fake_B = criterion_GAN(pred_fake_B, torch.zeros_like(pred_fake_B).to(device))
    d_loss_B = loss_real_B + loss_fake_B  # Pas d'op√©ration in-place ici
    d_loss_B.backward()
    optimizer_D_B.step()

    if epoch % display_interval == 0:
        show_images(real_A, fake_B, epoch)
        print(f'Epoch [{epoch+1}/{num_epochs}], g_loss: {g_loss.item():.4f}, d_loss_A: {d_loss_A.item():.4f}, d_loss_B: {d_loss_B.item():.4f}')

"""import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import random

# Dataset personnalis√© pour une seule image
class SingleImageDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Choisir une seule image al√©atoire
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        # Transformation si n√©cessaire
        if self.transform:
            image = self.transform(image)

        return image, image_path  # Retourne l'image et son chemin

# Transformations pour pr√©traiter les images
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset et choisir une seule image de fa√ßon al√©atoire
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'  # Remplace par le chemin r√©el vers ton dossier d'images
dataset = SingleImageDataset(image_dir, transform=transform)

# Choisir un indice al√©atoire
random_idx = random.randint(0, len(dataset)-1)  # Choisir un indice al√©atoire
real_image, image_path = dataset[random_idx]  # R√©cup√©rer l'image et le chemin

# Ajouter une dimension de batch (1, 3, 128, 128)
real_image = real_image.unsqueeze(0)  # Forme attendue: (1, 3, 128, 128)

# Afficher le chemin de l'image choisie
print(f'Image choisie : {image_path}')

# Mod√®le g√©n√©rateur
class Generator(nn.Module):
    def __init__(self, z_dim=100):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + 1, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 3 * 128 * 128),
            nn.Tanh()
        )

    def forward(self, z, age):
        # Concatenation du bruit et de l'√¢ge
        x = torch.cat([z, age], dim=1)
        x = self.fc(x)
        x = x.view(-1, 3, 128, 128)  # Redimensionner pour avoir une image 128x128
        return x

# Mod√®le discriminateur
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten()
        )
        self.fc = nn.Sequential(
            nn.Linear(512 * 8 * 8, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.model(x)
        x = self.fc(x)
        return x

# Initialisation des mod√®les
z_dim = 100  # Taille du bruit
device = torch.device("cpu")  # Utilisation du CPU

generator = Generator(z_dim=z_dim).to(device)
discriminator = Discriminator().to(device)

# Optimiseur
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# Crit√®re
criterion = nn.BCELoss()

# Fonction pour afficher les images
def show_images(real_image, fake_image, epoch):
    real_image = real_image / 2 + 0.5  # D√©normaliser les images
    fake_image = fake_image / 2 + 0.5  # D√©normaliser les images

    # Supprimer la premi√®re dimension (batch) pour avoir une image de forme (3, 128, 128)
    real_image = real_image.squeeze(0)  # (3, 128, 128)
    fake_image = fake_image.squeeze(0)  # (3, 128, 128)

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))

    # Affichage de l'image r√©elle
    axes[0].imshow(real_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title('Image r√©elle')
    axes[0].axis('off')

    # Affichage de l'image vieillie
    axes[1].imshow(fake_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title('Image vieillie')
    axes[1].axis('off')

    plt.suptitle(f'Epoch {epoch+1}')
    plt.show()

# Entra√Ænement
num_epochs = 10
batch_counter = 0  # Compteur de batchs
for epoch in range(num_epochs):
    z = torch.randn(1, z_dim).to(device)  # G√©n√©rer du bruit pour le g√©n√©rateur

    # Ajouter un √¢ge au bruit (par exemple, ajouter 30 ans)
    age = torch.tensor([[30]]).float().to(device)  # √Çge fix√© √† 30 ans

    # 1. G√©n√©rer une image vieillie √† partir de l'image r√©elle
    fake_image = generator(z, age)

    # 2. Calculer les pertes et faire la mise √† jour
    optimizer_G.zero_grad()
    outputs_fake = discriminator(fake_image)
    g_loss = criterion(outputs_fake.view(-1, 1), torch.ones(1, 1).to(device))  # Utiliser 1 comme label r√©el
    g_loss.backward()
    optimizer_G.step()

    # Affichage p√©riodique des r√©sultats tous les 1 epoch
    if epoch % 1 == 0:
        show_images(real_image, fake_image, epoch)
        print(f'Epoch [{epoch+1}/{num_epochs}], g_loss: {g_loss.item():.4f}')

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Dataset personnalis√© pour le dataset UTKFace Cropped
class UTKFaceCroppedDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Chargement de l'image
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        # Extraction de l'√¢ge depuis le nom de fichier (format: <age>_<gender>_<race>.jpg)
        filename = os.path.basename(image_path)
        age = int(filename.split('_')[0])  # R√©cup√®re l'√¢ge depuis le nom du fichier

        # Transformation si n√©cessaire
        if self.transform:
            image = self.transform(image)

        # Retourne l'image et l'√¢ge
        return image, torch.tensor(age, dtype=torch.float32)

# Transformations pour pr√©traiter les images
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset UTKFace Cropped
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'  # Remplace par le chemin r√©el vers ton dossier d'images
dataset = UTKFaceCroppedDataset(image_dir, transform=transform)

# Choisir une seule image pour l'entra√Ænement
selected_idx = 5  # Choisissez un indice pour s√©lectionner une seule image, ici index 5
real_image, real_age = dataset[selected_idx]  # R√©cup√©rer l'image et l'√¢ge correspondant

# Dataloader avec une seule image
train_loader = DataLoader([ (real_image, real_age) ], batch_size=1, shuffle=False)

# Mod√®le g√©n√©rateur
class Generator(nn.Module):
    def __init__(self, z_dim=100, age_dim=1):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + age_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 3 * 128 * 128),
            nn.Tanh()
        )

    def forward(self, z, age):
        # Concatenation du bruit et de l'√¢ge
        x = torch.cat([z, age], dim=1)
        x = self.fc(x)
        x = x.view(-1, 3, 128, 128)  # Redimensionner pour avoir une image 128x128
        return x

# Mod√®le discriminateur
class Discriminator(nn.Module):
    def __init__(self, age_dim=1):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),  # Premi√®re couche de convolution
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten()
        )
        self.age_embed = nn.Linear(age_dim, 256)  # Embedding de l'√¢ge
        self.fc = nn.Sequential(
            nn.Linear(512 * 8 * 8 + 256, 1),  # Ajouter l'√¢ge √† la fin avant de classifier
            nn.Sigmoid()
        )

    def forward(self, x, age):
        # Passer l'image dans le mod√®le
        x = self.model(x)

        # Embedding de l'√¢ge
        age_embedded = self.age_embed(age).view(age.size(0), -1)  # Applatir l'√¢ge

        # Concatenate l'√¢ge avec les caract√©ristiques de l'image
        x = torch.cat([x, age_embedded], dim=1)  # Ajouter l'√¢ge aux caract√©ristiques extraites de l'image

        # Classification finale
        x = self.fc(x)
        return x

# Initialisation des mod√®les
z_dim = 100
age_dim = 1

# Utilisation du CPU
device = torch.device("cpu")

# Envoi des mod√®les sur le CPU
generator = Generator(z_dim=z_dim, age_dim=age_dim).to(device)
discriminator = Discriminator(age_dim=age_dim).to(device)

# Optimiseur
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# Crit√®re
criterion = nn.BCELoss()

# Fonction pour afficher les images
def show_images(real_image, fake_image, real_age, fake_age, epoch, batch_num):
    real_image = real_image / 2 + 0.5  # D√©normaliser les images
    fake_image = fake_image / 2 + 0.5  # D√©normaliser les images

    # Supprimer la premi√®re dimension (batch) pour avoir une image de forme (3, 128, 128)
    real_image = real_image.squeeze(0)  # (3, 128, 128)
    fake_image = fake_image.squeeze(0)  # (3, 128, 128)

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))

    # Affichage de l'image r√©elle et de son √¢ge
    axes[0].imshow(real_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title(f'Real Age: {real_age.item()}')  # Afficher l'√¢ge r√©el
    axes[0].axis('off')  # Supprimer les axes pour une meilleure visualisation

    # Affichage de l'image fake et de l'√¢ge pr√©dit (+30)
    axes[1].imshow(fake_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title(f'Predicted Age: {fake_age.item()}')  # Afficher l'√¢ge pr√©dit (age r√©el + 30)
    axes[1].axis('off')  # Supprimer les axes pour une meilleure visualisation

    plt.suptitle(f'Epoch {epoch+1}, Batch {batch_num+1}')
    plt.show()

# Entra√Ænement
num_epochs = 10
batch_counter = 0  # Compteur de batchs
for epoch in range(num_epochs):
    for batch_num, (real_images, real_ages) in enumerate(train_loader):
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        real_ages = real_ages.float().to(device).view(-1, 1)  # Convertir l'√¢ge en float et redimensionner

        # Labels r√©els pour le discriminateur
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # S√©lectionner une seule image et son √¢ge
        real_image = real_images[0].unsqueeze(0)  # Image r√©elle de taille (1, 3, 128, 128)
        real_age = real_ages[0].unsqueeze(0)      # √Çge r√©el de taille (1, 1)

        # üîπ 1. Avec de vraies images
        outputs_real = discriminator(real_image, real_age)
        d_loss_real = criterion(outputs_real.view(-1, 1), real_labels[:1])  # Utiliser la premi√®re √©tiquette
        d_loss_real.backward()

        # üîπ 2. Avec des images g√©n√©r√©es
        z = torch.randn(1, z_dim).to(device)  # G√©n√©rer du bruit pour le g√©n√©rateur
        fake_age = real_age + 30  # Ajouter un vieillissement fixe de 30 ans
        fake_image = generator(z, fake_age)  # G√©n√©rer une image avec l'√¢ge vieillissant

        outputs_fake = discriminator(fake_image.detach(), fake_age)  # Ne pas r√©tropropager dans le g√©n√©rateur
        d_loss_fake = criterion(outputs_fake.view(-1, 1), fake_labels[:1])  # Utiliser la premi√®re √©tiquette
        d_loss_fake.backward()

        optimizer_D.step()

        # üîπ Mise √† jour du g√©n√©rateur
        optimizer_G.zero_grad()
        outputs_fake_gen = discriminator(fake_image, fake_age)
        g_loss = criterion(outputs_fake_gen.view(-1, 1), real_labels[:1])  # Utiliser la premi√®re √©tiquette
        g_loss.backward()

        optimizer_G.step()

        # Affichage p√©riodique des r√©sultats tous les 50 batchs
        batch_counter += 1
        if batch_counter % 50 == 0:  # Afficher les images tous les 50 batchs
            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_num+1}/{len(train_loader)}], d_loss: {d_loss_real.item() + d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}')
            show_images(real_image, fake_image, real_age, fake_age, epoch, batch_num)

    # Sauvegarde des mod√®les √† la fin de chaque √©poque
    torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')
    torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')
    print(f'Models saved for epoch {epoch+1}')"
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Dataset personnalis√© pour le dataset UTKFace Cropped
class UTKFaceCroppedDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Chargement de l'image
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        # Extraction de l'√¢ge depuis le nom de fichier (format: <age>_<gender>_<race>.jpg)
        filename = os.path.basename(image_path)
        age = int(filename.split('_')[0])  # R√©cup√®re l'√¢ge depuis le nom du fichier

        # Transformation si n√©cessaire
        if self.transform:
            image = self.transform(image)

        # Retourne l'image et l'√¢ge
        return image, torch.tensor(age, dtype=torch.float32)

# Transformations pour pr√©traiter les images
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset UTKFace Cropped
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'  # Remplace par le chemin r√©el vers ton dossier d'images
dataset = UTKFaceCroppedDataset(image_dir, transform=transform)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Mod√®le g√©n√©rateur
class Generator(nn.Module):
    def __init__(self, z_dim=100, age_dim=1):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + age_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 3 * 128 * 128),
            nn.Tanh()
        )

    def forward(self, z, age):
        # Concatenation du bruit et de l'√¢ge
        x = torch.cat([z, age], dim=1)
        x = self.fc(x)
        x = x.view(-1, 3, 128, 128)  # Redimensionner pour avoir une image 128x128
        return x

# Mod√®le discriminateur
class Discriminator(nn.Module):
    def __init__(self, age_dim=1):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),  # Premi√®re couche de convolution
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten()
        )
        self.age_embed = nn.Linear(age_dim, 256)  # Embedding de l'√¢ge
        self.fc = nn.Sequential(
            nn.Linear(512 * 8 * 8 + 256, 1),  # Ajouter l'√¢ge √† la fin avant de classifier
            nn.Sigmoid()
        )

    def forward(self, x, age):
        # Passer l'image dans le mod√®le
        x = self.model(x)

        # Embedding de l'√¢ge
        age_embedded = self.age_embed(age).view(age.size(0), -1)  # Applatir l'√¢ge

        # Concatenate l'√¢ge avec les caract√©ristiques de l'image
        x = torch.cat([x, age_embedded], dim=1)  # Ajouter l'√¢ge aux caract√©ristiques extraites de l'image

        # Classification finale
        x = self.fc(x)
        return x

# Initialisation des mod√®les
z_dim = 100
age_dim = 1

# Utilisation du CPU
device = torch.device("cpu")

# Envoi des mod√®les sur le CPU
generator = Generator(z_dim=z_dim, age_dim=age_dim).to(device)
discriminator = Discriminator(age_dim=age_dim).to(device)

# Optimiseur
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# Crit√®re
criterion = nn.BCELoss()

# Fonction pour afficher les images
def show_images(real_image, fake_image, real_age, fake_age, epoch, batch_num):
    real_image = real_image / 2 + 0.5  # D√©normaliser les images
    fake_image = fake_image / 2 + 0.5  # D√©normaliser les images

    # Supprimer la premi√®re dimension (batch) pour avoir une image de forme (3, 128, 128)
    real_image = real_image.squeeze(0)  # (3, 128, 128)
    fake_image = fake_image.squeeze(0)  # (3, 128, 128)

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))

    # Affichage de l'image r√©elle et de son √¢ge
    axes[0].imshow(real_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title(f'Real Age: {real_age.item()}')  # Afficher l'√¢ge r√©el
    axes[0].axis('off')  # Supprimer les axes pour une meilleure visualisation

    # Affichage de l'image fake et de l'√¢ge pr√©dit (+30)
    axes[1].imshow(fake_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title(f'Predicted Age: {fake_age.item()}')  # Afficher l'√¢ge pr√©dit (age r√©el + 30)
    axes[1].axis('off')  # Supprimer les axes pour une meilleure visualisation

    plt.suptitle(f'Epoch {epoch+1}, Batch {batch_num+1}')
    plt.show()

# Entra√Ænement
num_epochs = 10
batch_counter = 0  # Compteur de batchs
for epoch in range(num_epochs):
    for batch_num, (real_images, real_ages) in enumerate(train_loader):
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        real_ages = real_ages.float().to(device).view(-1, 1)  # Convertir l'√¢ge en float et redimensionner

        # Labels r√©els pour le discriminateur
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # S√©lectionner une seule image et son √¢ge
        real_image = real_images[0].unsqueeze(0)  # Image r√©elle de taille (1, 3, 128, 128)
        real_age = real_ages[0].unsqueeze(0)      # √Çge r√©el de taille (1, 1)

        # üîπ 1. Avec de vraies images
        outputs_real = discriminator(real_image, real_age)
        d_loss_real = criterion(outputs_real.view(-1, 1), real_labels[:1])  # Utiliser la premi√®re √©tiquette
        d_loss_real.backward()

        # üîπ 2. Avec des images g√©n√©r√©es
        z = torch.randn(1, z_dim).to(device)  # G√©n√©rer du bruit pour le g√©n√©rateur
        fake_age = real_age + 30  # Ajouter un vieillissement fixe de 30 ans
        fake_image = generator(z, fake_age)  # G√©n√©rer une image avec l'√¢ge vieillissant

        outputs_fake = discriminator(fake_image.detach(), fake_age)  # Ne pas r√©tropropager dans le g√©n√©rateur
        d_loss_fake = criterion(outputs_fake.view(-1, 1), fake_labels[:1])  # Utiliser la premi√®re √©tiquette
        d_loss_fake.backward()

        optimizer_D.step()

        # üîπ Mise √† jour du g√©n√©rateur
        optimizer_G.zero_grad()
        outputs_fake_gen = discriminator(fake_image, fake_age)
        g_loss = criterion(outputs_fake_gen.view(-1, 1), real_labels[:1])  # Utiliser la premi√®re √©tiquette
        g_loss.backward()

        optimizer_G.step()

        # Affichage p√©riodique des r√©sultats tous les 50 batchs
        batch_counter += 1
        if batch_counter % 50 == 0:  # Afficher les images tous les 50 batchs
            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_num+1}/{len(train_loader)}], d_loss: {d_loss_real.item() + d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}')
            show_images(real_image, fake_image, real_age, fake_age, epoch, batch_num)

    # Sauvegarde des mod√®les √† la fin de chaque √©poque
    torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')
    torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')
    print(f'Models saved for epoch {epoch+1}')

# ci-desossu bon √ßa marche mais probleme taille tenseur affichage imshow
"""import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Dataset personnalis√© pour le dataset UTKFace Cropped
class UTKFaceCroppedDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Chargement de l'image
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        # Extraction de l'√¢ge depuis le nom de fichier (format: <age>_<gender>_<race>.jpg)
        filename = os.path.basename(image_path)
        age = int(filename.split('_')[0])  # R√©cup√®re l'√¢ge depuis le nom du fichier

        # Transformation si n√©cessaire
        if self.transform:
            image = self.transform(image)

        # Retourne l'image et l'√¢ge
        return image, torch.tensor(age, dtype=torch.float32)

# Transformations pour pr√©traiter les images
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset UTKFace Cropped
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'  # Remplace par le chemin r√©el vers ton dossier d'images
dataset = UTKFaceCroppedDataset(image_dir, transform=transform)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Mod√®le g√©n√©rateur
class Generator(nn.Module):
    def __init__(self, z_dim=100, age_dim=1):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + age_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 3 * 128 * 128),
            nn.Tanh()
        )

    def forward(self, z, age):
        # Concatenation du bruit et de l'√¢ge
        x = torch.cat([z, age], dim=1)
        x = self.fc(x)
        x = x.view(-1, 3, 128, 128)  # Redimensionner pour avoir une image 128x128
        return x

# Mod√®le discriminateur
class Discriminator(nn.Module):
    def __init__(self, age_dim=1):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1),  # Premi√®re couche de convolution
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(256, 512, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten()
        )
        self.age_embed = nn.Linear(age_dim, 256)  # Embedding de l'√¢ge
        self.fc = nn.Sequential(
            nn.Linear(512 * 8 * 8 + 256, 1),  # Ajouter l'√¢ge √† la fin avant de classifier
            nn.Sigmoid()
        )

    def forward(self, x, age):
        # Passer l'image dans le mod√®le
        x = self.model(x)

        # Embedding de l'√¢ge
        age_embedded = self.age_embed(age).view(age.size(0), -1)  # Applatir l'√¢ge

        # Concatenate l'√¢ge avec les caract√©ristiques de l'image
        x = torch.cat([x, age_embedded], dim=1)  # Ajouter l'√¢ge aux caract√©ristiques extraites de l'image

        # Classification finale
        x = self.fc(x)
        return x

# Initialisation des mod√®les
z_dim = 100
age_dim = 1

# Utilisation du CPU
device = torch.device("cpu")

# Envoi des mod√®les sur le CPU
generator = Generator(z_dim=z_dim, age_dim=age_dim).to(device)
discriminator = Discriminator(age_dim=age_dim).to(device)

# Optimiseur
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# Crit√®re
criterion = nn.BCELoss()

# Fonction pour afficher les images
def show_images(real_image, fake_image, real_age, fake_age, epoch, batch_num):
    real_image = real_image / 2 + 0.5  # D√©normaliser les images
    fake_image = fake_image / 2 + 0.5  # D√©normaliser les images

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))
    axes[0].imshow(real_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title(f'Real Age: {real_age.item()}')
    axes[1].imshow(fake_image.permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title(f'Fake Age: {fake_age.item()}')
    plt.suptitle(f'Epoch {epoch+1}, Batch {batch_num+1}')
    plt.show()

# Entra√Ænement
# Entra√Ænement
num_epochs = 10
batch_counter = 0  # Compteur de batchs
for epoch in range(num_epochs):
    for batch_num, (real_images, real_ages) in enumerate(train_loader):
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        real_ages = real_ages.float().to(device).view(-1, 1)  # Convertir l'√¢ge en float et redimensionner

        # Labels r√©els pour le discriminateur
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # S√©lectionner une seule image et son √¢ge
        real_image = real_images[0].unsqueeze(0)  # Image r√©elle de taille (1, 3, 128, 128)
        real_age = real_ages[0].unsqueeze(0)      # √Çge r√©el de taille (1, 1)

        # üîπ 1. Avec de vraies images
        outputs_real = discriminator(real_image, real_age)
        d_loss_real = criterion(outputs_real.view(-1, 1), real_labels[:1])  # Utiliser la premi√®re √©tiquette
        d_loss_real.backward()

        # üîπ 2. Avec des images g√©n√©r√©es
        z = torch.randn(1, z_dim).to(device)  # G√©n√©rer du bruit pour le g√©n√©rateur
        fake_age = real_age + 30  # Ajouter un vieillissement fixe de 30 ans
        fake_image = generator(z, fake_age)  # G√©n√©rer une image avec l'√¢ge vieillissant

        outputs_fake = discriminator(fake_image.detach(), fake_age)  # Ne pas r√©tropropager dans le g√©n√©rateur
        d_loss_fake = criterion(outputs_fake.view(-1, 1), fake_labels[:1])  # Utiliser la premi√®re √©tiquette
        d_loss_fake.backward()

        optimizer_D.step()

        # üîπ Mise √† jour du g√©n√©rateur
        optimizer_G.zero_grad()
        outputs_fake_gen = discriminator(fake_image, fake_age)
        g_loss = criterion(outputs_fake_gen.view(-1, 1), real_labels[:1])  # Utiliser la premi√®re √©tiquette
        g_loss.backward()

        optimizer_G.step()

        # Affichage p√©riodique des r√©sultats tous les 50 batchs
        batch_counter += 1
        if batch_counter % 50 == 0:  # Afficher les images tous les 50 batchs
            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_num+1}/{len(train_loader)}], d_loss: {d_loss_real.item() + d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}')
            show_images(real_image, fake_image, real_age, fake_age, epoch, batch_num)

    # Sauvegarde des mod√®les √† la fin de chaque √©poque
    torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')
    torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')
    print(f'Models saved for epoch {epoch+1}')"""