# -*- coding: utf-8 -*-
"""vikenbloc4GANvielli19h.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aC5rX5DoCgBXNMvrJX-7-5mdXm862F42
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import time

# Dataset personnalis√© pour le dataset UTKFace Cropped
class UTKFaceCroppedDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Chargement de l'image
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        # Extraction de l'√¢ge depuis le nom de fichier (format: <age>_<gender>_<race>.jpg)
        filename = os.path.basename(image_path)
        age = int(filename.split('_')[0])  # R√©cup√®re l'√¢ge depuis le nom du fichier

        # Transformation si n√©cessaire
        if self.transform:
            image = self.transform(image)

        # Retourne l'image et l'√¢ge
        return image, torch.tensor(age, dtype=torch.float32)

# Transformations pour pr√©traiter les images
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # R√©duire la taille pour acc√©l√©rer le calcul
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset UTKFace Cropped
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'  # Remplace par le chemin r√©el vers ton dossier d'images
dataset = UTKFaceCroppedDataset(image_dir, transform=transform)
train_loader = DataLoader(dataset, batch_size=16, shuffle=True)

# Mod√®le g√©n√©rateur simplifi√©
class Generator(nn.Module):
    def __init__(self, z_dim=100, age_dim=1):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + age_dim, 128),  # R√©duire la taille pour simplifier
            nn.ReLU(True),
            nn.Linear(128, 256),
            nn.ReLU(True),
            nn.Linear(256, 3 * 64 * 64),  # R√©duire la taille de l'image g√©n√©r√©e √† 64x64
            nn.Tanh()
        )

    def forward(self, z, age):
        # Concatenation du bruit et de l'√¢ge
        x = torch.cat([z, age], dim=1)
        x = self.fc(x)
        x = x.view(-1, 3, 64, 64)  # Redimensionner pour avoir une image 64x64
        return x

# Mod√®le discriminateur simplifi√©
class Discriminator(nn.Module):
    def __init__(self, age_dim=1):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 4, 2, 1),  # R√©duire les filtres pour simplifier
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten()
        )
        self.age_embed = nn.Linear(age_dim, 128)  # Embedding de l'√¢ge
        self.fc = nn.Sequential(
            nn.Linear(64 * 16 * 16 + 128, 1),  # Ajuster en fonction de la taille des images
            nn.Sigmoid()
        )

    def forward(self, x, age):
        # Passer l'image dans le mod√®le
        x = self.model(x)

        # Embedding de l'√¢ge
        age_embedded = self.age_embed(age).view(age.size(0), -1)  # Applatir l'√¢ge

        # Concatenate l'√¢ge avec les caract√©ristiques extraites de l'image
        x = torch.cat([x, age_embedded], dim=1)  # Ajouter l'√¢ge aux caract√©ristiques extraites de l'image

        # Classification finale
        x = self.fc(x)
        return x

# Initialisation des mod√®les
z_dim = 100
age_dim = 1

# Utilisation du CPU
device = torch.device("cpu")

# Envoi des mod√®les sur le CPU
generator = Generator(z_dim=z_dim, age_dim=age_dim).to(device)
discriminator = Discriminator(age_dim=age_dim).to(device)

# Optimiseur
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# Crit√®re
criterion = nn.BCELoss()

# S√©lectionner une image sp√©cifique (par exemple, la premi√®re image du dataset)
real_image, real_age = dataset[0]  # Utiliser la premi√®re image pour l'affichage constant
real_image = real_image.unsqueeze(0).to(device)  # Ajouter une dimension batch
real_age = real_age.unsqueeze(0).to(device).view(-1, 1)  # Ajouter une dimension batch et redimensionner l'√¢ge

# Fonction pour afficher les images
def show_images(real_image, fake_image, real_age, fake_age, epoch):
    real_image = real_image / 2 + 0.5  # D√©normaliser l'image
    fake_image = fake_image / 2 + 0.5  # D√©normaliser l'image

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))
    axes[0].imshow(real_image[0].permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title(f'Real Age: {real_age[0].item()}')
    axes[1].imshow(fake_image[0].permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title(f'Fake Age: {fake_age[0].item()}')
    plt.show()

# Entra√Ænement
num_epochs = 10
for epoch in range(num_epochs):
    start_time = time.time()  # D√©marrer le chronom√®tre pour l'√©poch
    for i, (real_images, real_ages) in enumerate(train_loader):
        batch_start_time = time.time()  # Chronom√®tre pour chaque batch
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        real_ages = real_ages.float().to(device).view(-1, 1)  # Convertir l'√¢ge en float et redimensionner

        # Labels r√©els pour le discriminateur
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # üîπ 1. Avec de vraies images
        outputs_real = discriminator(real_images, real_ages)
        d_loss_real = criterion(outputs_real.view(-1, 1), real_labels)
        d_loss_real.backward()

        # üîπ 2. Avec des images g√©n√©r√©es
        z = torch.randn(batch_size, z_dim).to(device)  # G√©n√©rer du bruit pour le g√©n√©rateur
        fake_ages = real_ages + 30  # Ajouter un vieillissement fixe de 30 ans
        fake_images = generator(z, fake_ages)  # G√©n√©rer une image avec l'√¢ge vieillissant

        outputs_fake = discriminator(fake_images.detach(), fake_ages)  # Ne pas r√©tropropager dans le g√©n√©rateur
        d_loss_fake = criterion(outputs_fake.view(-1, 1), fake_labels)
        d_loss_fake.backward()

        optimizer_D.step()

        # üîπ Mise √† jour du g√©n√©rateur
        optimizer_G.zero_grad()
        outputs_fake_gen = discriminator(fake_images, fake_ages)
        g_loss = criterion(outputs_fake_gen.view(-1, 1), real_labels)
        g_loss.backward()

        optimizer_G.step()

        # Affichage p√©riodique des r√©sultats (toutes les 50 √©tapes)
        if (i + 1) % 50 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], d_loss: {d_loss_real.item() + d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}')
            show_images(real_image, fake_images, real_ages, fake_ages, epoch)

        batch_duration = time.time() - batch_start_time  # Temps √©coul√© pour ce batch
        print(f"Batch {i+1}, Dur√©e du batch: {batch_duration:.2f} secondes")

    epoch_duration = time.time() - start_time  # Temps total pour une √©poque
    print(f"Dur√©e totale de l'√©poque {epoch+1}: {epoch_duration:.2f} secondes")

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import time

# Dataset personnalis√© pour le dataset UTKFace Cropped
class UTKFaceCroppedDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        self.image_dir = image_dir
        self.transform = transform
        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Chargement de l'image
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')

        # Extraction de l'√¢ge depuis le nom de fichier (format: <age>_<gender>_<race>.jpg)
        filename = os.path.basename(image_path)
        age = int(filename.split('_')[0])  # R√©cup√®re l'√¢ge depuis le nom du fichier

        # Transformation si n√©cessaire
        if self.transform:
            image = self.transform(image)

        # Retourne l'image et l'√¢ge
        return image, torch.tensor(age, dtype=torch.float32)

# Transformations pour pr√©traiter les images
transform = transforms.Compose([
    transforms.Resize((64, 64)),  # R√©duire la taille pour acc√©l√©rer le calcul
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

# Charger le dataset UTKFace Cropped
image_dir = 'drive/MyDrive/Bloc4Viken/utkcropped'  # Remplace par le chemin r√©el vers ton dossier d'images
dataset = UTKFaceCroppedDataset(image_dir, transform=transform)
train_loader = DataLoader(dataset, batch_size=16, shuffle=True)

# Mod√®le g√©n√©rateur simplifi√©
class Generator(nn.Module):
    def __init__(self, z_dim=100, age_dim=1):
        super(Generator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(z_dim + age_dim, 128),  # R√©duire la taille pour simplifier
            nn.ReLU(True),
            nn.Linear(128, 256),
            nn.ReLU(True),
            nn.Linear(256, 3 * 64 * 64),  # R√©duire la taille de l'image g√©n√©r√©e √† 64x64
            nn.Tanh()
        )

    def forward(self, z, age):
        # Concatenation du bruit et de l'√¢ge
        x = torch.cat([z, age], dim=1)
        x = self.fc(x)
        x = x.view(-1, 3, 64, 64)  # Redimensionner pour avoir une image 64x64
        return x

# Mod√®le discriminateur simplifi√©
class Discriminator(nn.Module):
    def __init__(self, age_dim=1):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 4, 2, 1),  # R√©duire les filtres pour simplifier
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Flatten()
        )
        self.age_embed = nn.Linear(age_dim, 128)  # Embedding de l'√¢ge
        self.fc = nn.Sequential(
            nn.Linear(64 * 16 * 16 + 128, 1),  # Ajuster en fonction de la taille des images
            nn.Sigmoid()
        )

    def forward(self, x, age):
        # Passer l'image dans le mod√®le
        x = self.model(x)

        # Embedding de l'√¢ge
        age_embedded = self.age_embed(age).view(age.size(0), -1)  # Applatir l'√¢ge

        # Concatenate l'√¢ge avec les caract√©ristiques de l'image
        x = torch.cat([x, age_embedded], dim=1)  # Ajouter l'√¢ge aux caract√©ristiques extraites de l'image

        # Classification finale
        x = self.fc(x)
        return x

# Initialisation des mod√®les
z_dim = 100
age_dim = 1

# Utilisation du CPU
device = torch.device("cpu")

# Envoi des mod√®les sur le CPU
generator = Generator(z_dim=z_dim, age_dim=age_dim).to(device)
discriminator = Discriminator(age_dim=age_dim).to(device)

# Optimiseur
lr = 0.0002
betas = (0.5, 0.999)
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=betas)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=betas)

# Crit√®re
criterion = nn.BCELoss()

# Fonction pour afficher les images
def show_images(real_images, fake_images, real_ages, fake_ages, epoch):
    real_images = real_images / 2 + 0.5  # D√©normaliser les images
    fake_images = fake_images / 2 + 0.5  # D√©normaliser les images

    fig, axes = plt.subplots(1, 2, figsize=(8, 4))
    axes[0].imshow(real_images[0].permute(1, 2, 0).cpu().detach().numpy())
    axes[0].set_title(f'Real Age: {real_ages[0].item()}')
    axes[1].imshow(fake_images[0].permute(1, 2, 0).cpu().detach().numpy())
    axes[1].set_title(f'Fake Age: {fake_ages[0].item()}')
    plt.show()

# Entra√Ænement
num_epochs = 10
for epoch in range(num_epochs):
    start_time = time.time()  # D√©marrer le chronom√®tre pour l'√©poch
    for i, (real_images, real_ages) in enumerate(train_loader):
        batch_start_time = time.time()  # Chronom√®tre pour chaque batch
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        real_ages = real_ages.float().to(device).view(-1, 1)  # Convertir l'√¢ge en float et redimensionner

        # Labels r√©els pour le discriminateur
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # üîπ 1. Avec de vraies images
        outputs_real = discriminator(real_images, real_ages)
        d_loss_real = criterion(outputs_real.view(-1, 1), real_labels)
        d_loss_real.backward()

        # üîπ 2. Avec des images g√©n√©r√©es
        z = torch.randn(batch_size, z_dim).to(device)  # G√©n√©rer du bruit pour le g√©n√©rateur
        fake_ages = real_ages + 30  # Ajouter un vieillissement fixe de 30 ans
        fake_images = generator(z, fake_ages)  # G√©n√©rer une image avec l'√¢ge vieillissant

        outputs_fake = discriminator(fake_images.detach(), fake_ages)  # Ne pas r√©tropropager dans le g√©n√©rateur
        d_loss_fake = criterion(outputs_fake.view(-1, 1), fake_labels)
        d_loss_fake.backward()

        optimizer_D.step()

        # üîπ Mise √† jour du g√©n√©rateur
        optimizer_G.zero_grad()
        outputs_fake_gen = discriminator(fake_images, fake_ages)
        g_loss = criterion(outputs_fake_gen.view(-1, 1), real_labels)
        g_loss.backward()

        optimizer_G.step()

        # Affichage p√©riodique des r√©sultats (toutes les 50 √©tapes)
        if (i + 1) % 50 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_loader)}], d_loss: {d_loss_real.item() + d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}')
            show_images(real_images, fake_images, real_ages, fake_ages, epoch)

        batch_duration = time.time() - batch_start_time  # Temps √©coul√© pour ce batch
        print(f"Batch {i+1}, Dur√©e du batch: {batch_duration:.2f} secondes")

    epoch_duration = time.time() - start_time  # Temps total pour une √©poque
    print(f"Dur√©e totale de l'√©poque {epoch+1}: {epoch_duration:.2f} secondes")